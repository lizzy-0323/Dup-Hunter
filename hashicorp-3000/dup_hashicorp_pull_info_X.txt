[{"A_title": "(WIP) Update cloudfront behaviors to behave like lists and allow for ordering", "A_clean_title": ["wip", "updat", "cloudfront", "behavior", "behav", "like", "list", "allow", "order"], "B_title": "helper/schema: Make nested Set(s) in List(s) work (2)", "B_clean_title": ["helper", "schema", "make", "nest", "set", "list", "work"], "A_body": "#7253\n- Updated references to sets instead of lists\n- Updated tests so they pass\n- Successfully added ordered rules to cloudfront\n\nHowever, some setbacks:\nStill encountering a bug that maybe someone can help me with... I get an index out of bounds exception when I run `terraform apply` due to this line:\n\ncloudfront_distribution_configuration_structure.go\n`ForwardedValues:      expandForwardedValues(m[\"forwarded_values\"].(*schema.Set).List()[0].(map[string]interface{})),\n`\n\nThere may also be a bug in field_reader.go addrToSchema. I'm not sure that code is robust against crazy combinations of nested sets and lists.\n\nTODO:\n1. Fix index out of bounds exception\n2. Write new tests for this behavior\n3. Update documentation about the new syntax for cache_behaviors\n4. If necessary, concoct some migration plan from sets to lists... Then again, seemed to maybe work fine just making the changes to the tf file? Maybe to be safe, we can keep support for the set in a deprecated way.\n", "A_clean_body": ["7253", "updat", "refer", "set", "instead", "list", "updat", "test", "so", "they", "pass", "success", "ad", "order", "rule", "cloudfront", "howev", "some", "setback", "still", "encount", "bug", "that", "mayb", "someon", "help", "me", "get", "index", "out", "bound", "except", "when", "run", "terraform", "appli", "due", "thi", "line", "go", "cloudfront", "distribut", "configur", "structur", "forwardedvalu", "forward", "valu", "expandforwardedvalu", "expand", "forward", "valu", "forward", "valu", "*schema", "set", "list", "map", "string", "interfac", "there", "may", "also", "bug", "go", "field", "reader", "addrtoschema", "addr", "schema", "'m", "not", "sure", "that", "code", "robust", "against", "crazi", "combin", "nest", "set", "list", "todo", "fix", "index", "out", "bound", "except", "write", "new", "test", "thi", "behavior", "updat", "document", "about", "new", "syntax", "cach", "behavior", "necessari", "concoct", "some", "migrat", "plan", "set", "list", "then", "again", "seem", "mayb", "work", "fine", "just", "make", "chang", "tf", "file", "mayb", "safe", "we", "keep", "support", "set", "deprec", "way"], "B_body": "This is a second (patched) version of #7393 which had to be [reverted](https://github.com/hashicorp/terraform/pull/7436) because some acceptance tests were failing as part of the nightly run.\n\nRelated to #7253 & #7254\nSupersedes/fixes #7268\nBlocking #7395\n\n---\n\nThe only difference from the original PR is the last commit (`50fbe79`).\n\n---\n\nI managed to reproduce schema diff edge cases from the failing tests in `aws` provider and fix those. I added 3 new unit tests to cover this new functionality.\n\nI ran the [16 (previously failing)](https://gist.github.com/radeksimko/331ed5a2cb2ce7e84d13a3dcc9fd5331) aws acceptance tests, all are now passing. I also ran first `aws` **141** of total 464 acceptance tests which all (eventually) passed.\n\nI don't have a Fastly account so I would appreciate if someone could double check all acceptance tests are passing there too and generally run the whole shebang once again with this patch (possibly before merging).\n", "B_clean_body": ["thi", "second", "patch", "version", "7393", "which", "had", "revert", "http", "github", "com", "hashicorp", "terraform", "pull", "7436", "becaus", "some", "accept", "test", "were", "fail", "as", "part", "nightli", "run", "relat", "7253", "7254", "supersed", "fix", "7268", "block", "7395", "onli", "differ", "origin", "pr", "last", "commit", "50fbe79", "manag", "reproduc", "schema", "diff", "edg", "case", "fail", "test", "aw", "provid", "fix", "those", "ad", "new", "unit", "test", "cover", "thi", "new", "function", "ran", "16", "previous", "fail", "http", "github", "gist", "com", "radeksimko", "331ed5a2cb2ce7e84d13a3dcc9fd5331", "aw", "accept", "test", "all", "are", "now", "pass", "also", "ran", "first", "aw", "**141**", "total", "464", "accept", "test", "which", "all", "eventu", "pass", "n't", "have", "fastli", "account", "so", "would", "appreci", "someon", "could", "doubl", "check", "all", "accept", "test", "are", "pass", "there", "too", "gener", "run", "whole", "shebang", "onc", "again", "thi", "patch", "possibl", "befor", "merg"], "title_sim": [0.17920233051949522], "body_sim": [0.3607588389595555], "file_list_sim": 0, "overlap_files_len": 0, "code_sim": [0.0, 0.0], "location_sim": [0.0, 0.0], "pattern": 1, "time": 88}, {"A_title": "Add additional options to google provider", "A_clean_title": ["add", "addit", "option", "googl", "provid"], "B_title": "Make the device name for attached disks equal to the disk name, making provisioning disks easier", "B_clean_title": ["make", "devic", "name", "attach", "disk", "equal", "disk", "name", "make", "provis", "disk", "easier"], "A_body": "This PR adds disk device names and ability to create disks from snapshots\n", "A_clean_body": ["thi", "pr", "add", "disk", "devic", "name", "abil", "creat", "disk", "snapshot"], "B_body": "", "B_clean_body": [], "title_sim": [-0.0016903773797872206], "body_sim": [0.0], "file_list_sim": 0.25, "overlap_files_len": 1, "code_sim": [0.35176092848777013, 0.6793800004346184], "location_sim": [0.0, 0.0], "pattern": 0, "time": 14}, {"A_title": "Fixing Go Vet errors", "A_clean_title": ["fix", "go", "vet", "error"], "B_title": "Update Travis to use Go 1.6", "B_clean_title": ["updat", "travi", "use", "go"], "A_body": "", "A_clean_body": [], "B_body": "", "B_clean_body": [], "title_sim": [0.32182034982634744], "body_sim": [0.0], "file_list_sim": 0.5, "overlap_files_len": 2, "code_sim": [0.0, 0.0], "location_sim": [0.5581395348837209, 1.0], "pattern": 0, "time": 0}, {"A_title": "Compute private ip addresses of ENIs if they are not specified", "A_clean_title": ["comput", "privat", "ip", "address", "eni", "en", "they", "are", "not", "specifi"], "B_title": "provider/aws: Network Interface private ips can be computed", "B_clean_title": ["provid", "aw", "network", "interfac", "privat", "ip", "comput"], "A_body": "As AWS will assign the ENI an address\n\nAddresses #2729 \n", "A_clean_body": ["as", "aw", "will", "assign", "eni", "address", "address", "2729"], "B_body": "Fixes #2729\n", "B_clean_body": ["fix", "2729"], "title_sim": [0.3640268420976968], "body_sim": [0.022685448022494597], "file_list_sim": 0.5, "overlap_files_len": 1, "code_sim": [0.1448112870926553, 1.0000000000000002], "location_sim": [0.2222222222222222, 1.0], "pattern": 1, "time": 0}, {"A_title": "splitting an IAM ARN into a Name should return the last element", "A_clean_title": ["split", "iam", "arn", "into", "name", "return", "last", "element"], "B_title": "get profile name even if profile path exists", "B_clean_title": ["get", "profil", "name", "even", "profil", "path", "exist"], "A_body": "My `aws_iam_instance_profile` had a path of `/apps/<service>/` and a name of `<Service>Profile`.  When I build new instances, the tfstate file saved the value incorrectly.\n\n```\n\"iam_instance_profile\": \"apps\",\n```\n\nWhen running `terraform plan` I continued to get this.\n\n```\niam_instance_profile:              \"apps\" => \"<Service>Profile\" (forces new resource)\n```\n", "A_clean_body": ["my", "aw", "iam", "instanc", "profil", "had", "path", "app", "servic", "name", "servic", "profil", "when", "build", "new", "instanc", "tfstate", "file", "save", "valu", "incorrectli", "iam", "instanc", "profil", "app", "when", "run", "terraform", "plan", "continu", "get", "thi", "iam", "instanc", "profil", "app", "servic", "profil", "forc", "new", "resourc"], "B_body": "When terraform started persisting the instance profile name to the state the code used the second part of the instance profile ARN split on \"/\" where it should be using the last part of the ARN split on \"/\"\n", "B_clean_body": ["when", "terraform", "start", "persist", "instanc", "profil", "name", "state", "code", "use", "second", "part", "instanc", "profil", "arn", "split", "where", "it", "last", "part", "arn", "split"], "title_sim": [0.31279667249937937], "body_sim": [0.5484640161198102], "file_list_sim": 1.0, "overlap_files_len": 1, "code_sim": [0.16431761810327764, 0.16431761810327764], "location_sim": [1.0, 1.0], "pattern": 0, "time": 37}, {"A_title": "Handle `google_compute_instance_group_manager` not being found", "A_clean_title": ["handl", "googl", "comput", "instanc", "group", "manag", "not", "be", "found"], "B_title": "provider/google: Move 404 checking into a function in provider.go, call it from instance and IGM", "B_clean_title": ["provid", "googl", "move", "404", "check", "into", "function", "provid", "go", "call", "it", "instanc", "igm"], "A_body": "Mark the resource as no longer available.\r\n\r\nFixes #13943.", "A_clean_body": ["mark", "resourc", "as", "no", "longer", "avail", "fix", "13943"], "B_body": "Initial PR for #13943. It fixes the specific concern by adding in 404 checking for `resource_compute_instance_group_manager`, and also shows the new function being reused in `resource_compute_instance` (note that it also exposed a bug- if there is a 404, we should return `nil` instead of an error). If this looks good, I'll check it in and then open up a separate PR for the rest of the resources.", "B_clean_body": ["initi", "pr", "13943", "it", "fix", "specif", "concern", "by", "ad", "404", "check", "resourc", "comput", "instanc", "group", "manag", "also", "show", "new", "function", "be", "reus", "resourc", "comput", "instanc", "note", "that", "it", "also", "expos", "bug", "there", "404", "we", "return", "nil", "instead", "error", "thi", "look", "good", "'ll", "check", "it", "then", "open", "up", "separ", "pr", "rest", "resourc"], "title_sim": [0.29479977156412], "body_sim": [0.35837774250088206], "file_list_sim": 0.3333333333333333, "overlap_files_len": 1, "code_sim": [0.07978607940969805, 0.1387314868563328], "location_sim": [0.21951219512195122, 0.46153846153846156], "pattern": 1, "time": 0}, {"A_title": "Aurora rds", "A_clean_title": ["aurora", "rd"], "B_title": "add resource aws_rds_cluster_parameter_group", "B_clean_title": ["add", "resourc", "aw", "rd", "cluster", "paramet", "group"], "A_body": "This is pull request to add aws rds db cluster parameter group function.\n[GH-6568]\n", "A_clean_body": ["thi", "pull", "request", "add", "aw", "rd", "db", "cluster", "paramet", "group", "function", "gh", "6568"], "B_body": "This PR adds support for RDS Cluster Parameter Groups (see #5031, #5023). It's more or less a carbon copy of `aws_db_parameter_group`. \n\nI have a small question regarding error handling. `aws_db_parameter_group` [compares against `DBParameterGroupNotFoundFault`](https://github.com/hashicorp/terraform/blob/79dee04a98e20c10c500690f03d2a8f69f74420d/builtin/providers/aws/resource_aws_db_parameter_group.go#L255), not `DBParameterGroupNotFound`, which is the error code I've been observing in docs and during tests. Is that correct? I'm using `DBParameterGroupNotFound` for now.\n", "B_clean_body": ["thi", "pr", "add", "support", "rd", "cluster", "paramet", "group", "see", "5031", "5023", "it", "'s", "more", "or", "less", "carbon", "copi", "aw", "db", "paramet", "group", "have", "small", "question", "regard", "error", "handl", "aw", "db", "paramet", "group", "compar", "against", "dbparametergroupnotfoundfault", "db", "paramet", "group", "not", "found", "fault", "http", "go", "github", "aw", "db", "paramet", "group", "com", "hashicorp", "terraform", "blob", "79dee04a98e20c10c500690f03d2a8f69f74420d", "builtin", "provid", "aw", "resourc", "l255", "not", "dbparametergroupnotfound", "db", "paramet", "group", "not", "found", "which", "error", "code", "'ve", "been", "observ", "doc", "dure", "test", "that", "correct", "'m", "dbparametergroupnotfound", "db", "paramet", "group", "not", "found", "now"], "title_sim": [0.0], "body_sim": [0.5576970519535184], "file_list_sim": 0.2, "overlap_files_len": 2, "code_sim": [0.9680690209124272, 0.8817081258287143], "location_sim": [0.024727272727272726, 0.3695652173913043], "pattern": 0, "time": 76}, {"A_title": "provider/aws: Fix import of RouteTable with destination prefixes ", "A_clean_title": ["provid", "aw", "fix", "import", "routet", "rout", "tabl", "destin", "prefix"], "B_title": "provider/aws Skip importing routes for VPC endpoints", "B_clean_title": ["provid", "aw", "skip", "import", "rout", "vpc", "endpoint"], "A_body": "Route Tables can get routes that do not have a `DestinationCidrBlock` by way of `aws_vpc_endpoint`. These Routes are ignored in [reading `aws_route_table`](https://github.com/hashicorp/terraform/blob/master/builtin/providers/aws/resource_aws_route_table.go#L158-L162) and so we should ignore them here as well. \n\nFixes #8225 , adds test\n", "A_clean_body": ["rout", "tabl", "get", "rout", "that", "not", "have", "destinationcidrblock", "destin", "cidr", "block", "by", "way", "aw", "vpc", "endpoint", "these", "rout", "are", "ignor", "read", "aw", "rout", "tabl", "http", "go", "github", "aw", "rout", "tabl", "com", "hashicorp", "terraform", "blob", "master", "builtin", "provid", "aw", "resourc", "l158", "l162", "so", "we", "ignor", "them", "here", "as", "well", "fix", "8225", "add", "test"], "B_body": "- Same logic as in `resourceAwsRouteTableRead`\n- Fixes #8225 \n", "B_clean_body": ["same", "logic", "as", "resourceawsroutetableread", "resourc", "aw", "rout", "tabl", "read", "fix", "8225"], "title_sim": [0.651257354086462], "body_sim": [0.577322038003664], "file_list_sim": 0.5, "overlap_files_len": 1, "code_sim": [0.5493305033474444, 1.0], "location_sim": [0.15, 1.0], "pattern": 1, "time": 7}, {"A_title": "provider/aws: Change the way ARNs are built", "A_clean_title": ["provid", "aw", "chang", "way", "arn", "ar", "ns", "are", "built"], "B_title": "Use the new AWSClient.accountid when generating ARNs", "B_clean_title": ["use", "new", "awsclient", "accountid", "aw", "client", "when", "gener", "arn", "ar", "ns"], "A_body": "ARNs used to be build using the iamconn.GetUser func call. This wouldn't\nwork on some scenarios and was changed so that we can expose the\nAccountId and Region via meta\n\nThis commit just changes the build ARN funcs to use this new way of\ndoing things\n", "A_clean_body": ["arn", "ar", "ns", "use", "build", "iamconn", "getus", "get", "user", "func", "call", "thi", "wouldn't", "work", "some", "scenario", "wa", "chang", "so", "that", "we", "expos", "accountid", "account", "id", "region", "via", "meta", "thi", "commit", "just", "chang", "build", "arn", "func", "use", "thi", "new", "way", "do", "thing"], "B_body": "With the merge of #6385 we are now able to leverage the one-time collection of the AWS account id rather than trying to fetch it from multiple places in the code.\n", "B_clean_body": ["merg", "6385", "we", "are", "now", "abl", "leverag", "one", "time", "collect", "aw", "account", "id", "rather", "than", "tri", "fetch", "it", "multipl", "place", "code"], "title_sim": [0.6135393083916616], "body_sim": [0.3672992096294275], "file_list_sim": 0.875, "overlap_files_len": 7, "code_sim": [0.933515072352693, 0.939119491469997], "location_sim": [0.5726315789473684, 0.6181818181818182], "pattern": 0, "time": 38}, {"A_title": "helper/schema: allow set items with hyphens", "A_clean_title": ["helper", "schema", "allow", "set", "item", "hyphen"], "B_title": "Bug: Only prefix hashcode with TypeSet diff marker.", "B_clean_title": ["bug", "onli", "prefix", "hashcod", "typeset", "type", "set", "diff", "marker"], "A_body": "Fixes #1641\n\nThis fixes the way we replace \"-\" with \"~\" in computed sets to only consider the code. This allows set items with hyphens to work. They somewhat hilariously and sadly didn't work before.\n", "A_clean_body": ["fix", "1641", "thi", "fix", "way", "we", "replac", "comput", "set", "onli", "consid", "code", "thi", "allow", "set", "item", "hyphen", "work", "they", "somewhat", "hilari", "sadli", "did", "n't", "work", "befor"], "B_body": "This fixes the immediate problem discussed in #1641 by limiting the hyphen to tilde substitution with computed hashcodes only.\n", "B_clean_body": ["thi", "fix", "immedi", "problem", "discuss", "1641", "by", "limit", "hyphen", "tild", "substitut", "comput", "hashcod", "onli"], "title_sim": [0.23024378361071282], "body_sim": [0.2479872793906394], "file_list_sim": 0.5, "overlap_files_len": 2, "code_sim": [0.3720827283169109, 0.329168855724727], "location_sim": [0.329608938547486, 0.3933333333333333], "pattern": 1, "time": 0}, {"A_title": "provider/aws: Add epsilon to the regex date validation", "A_clean_title": ["provid", "aw", "add", "epsilon", "regex", "date", "valid"], "B_title": "provider/aws: Fix OnceADayWindowFormat Validator", "B_clean_title": ["provid", "aw", "fix", "onceadaywindowformat", "onc", "day", "window", "format", "valid"], "A_body": "Allows empty values for dates\r\n\r\nFixes: https://github.com/hashicorp/terraform/issues/11663", "A_clean_body": ["allow", "empti", "valu", "date", "fix", "http", "github", "com", "hashicorp", "terraform", "issu", "11663"], "B_body": "If an attribute that would normally be validated by `validateOnceADayWindowFormat()` is an empty string, in every case AWS supplies a default time window to use.\r\n\r\nThus, an empty string for these attributes is a valid value.\r\n\r\nFixes: #11663 ", "B_clean_body": ["attribut", "that", "would", "normal", "valid", "by", "validateonceadaywindowformat", "valid", "onc", "day", "window", "format", "empti", "string", "everi", "case", "aw", "suppli", "default", "time", "window", "use", "thu", "empti", "string", "these", "attribut", "valid", "valu", "fix", "11663"], "title_sim": [0.6042867259873481], "body_sim": [0.24822635850729746], "file_list_sim": 1.0, "overlap_files_len": 2, "code_sim": [0.22392573851651063, 0.22392573851651063], "location_sim": [0.6865671641791045, 0.6865671641791045], "pattern": 1, "time": 0}, {"A_title": "Adds support for uploading blobs to azure storage from local source", "A_clean_title": ["add", "support", "upload", "blob", "azur", "storag", "local", "sourc"], "B_title": "WIP: Adds ability to copy public blob", "B_clean_title": ["wip", "add", "abil", "copi", "public", "blob"], "A_body": "- adds \"source\", \"parallelism\", and \"attempts\" fields\n- supports both block and page type blobs\n- uploads run concurrently\n- page blobs skip empty byte ranges to efficiently upload large sparse\n  files\n- \"source\" expects an absolute path to a file on the local file\n  system\n- \"parallelism\" expects an integer value that indicates the number of\n  workers per CPU core to run for concurrent uploads\n- \"attempts\" expects an integer value for number of attempts to make per\n  page or block when uploading\n", "A_clean_body": ["add", "sourc", "parallel", "attempt", "field", "support", "both", "block", "page", "type", "blob", "upload", "run", "concurr", "page", "blob", "skip", "empti", "byte", "rang", "effici", "upload", "larg", "spars", "file", "sourc", "expect", "absolut", "path", "file", "local", "file", "system", "parallel", "expect", "integ", "valu", "that", "indic", "number", "worker", "per", "cpu", "core", "run", "concurr", "upload", "attempt", "expect", "integ", "valu", "number", "attempt", "make", "per", "page", "or", "block", "when", "upload"], "B_body": "Still working on this - want to make sure that private blobs can be copied. Tests may not be great.\n- can copy via a filepath up to azure\n- can also copy from one storage account to another (if public)\n\nSigned-off-by: Zachary Gershman zgershman@pivotal.io\n", "B_clean_body": ["still", "work", "thi", "want", "make", "sure", "that", "privat", "blob", "copi", "test", "may", "not", "great", "copi", "via", "filepath", "up", "azur", "also", "copi", "one", "storag", "account", "anoth", "public", "sign", "off", "by", "zachari", "gershman", "zgershman", "pivot", "io"], "title_sim": [0.15303650857790393], "body_sim": [0.17460566094606716], "file_list_sim": 1.0, "overlap_files_len": 2, "code_sim": [0.8577536837660138, 0.8577536837660138], "location_sim": [0.921, 0.921], "pattern": 0, "time": 2}, {"A_title": "provider/aws: test exposing sg rule race", "A_clean_title": ["provid", "aw", "test", "expos", "sg", "rule", "race"], "B_title": "provider/aws: Update Security Group Rules to Version 2", "B_clean_title": ["provid", "aw", "updat", "secur", "group", "rule", "version"], "A_body": "this test fails around 50% of the time for me - you can bump the\niterations up to 50 to get it to fail more often, but higher than that\nand you'll run into AWS account limits\n", "A_clean_body": ["thi", "test", "fail", "around", "50", "time", "me", "you", "bump", "iter", "up", "50", "get", "it", "fail", "more", "often", "but", "higher", "than", "that", "you", "'ll", "run", "into", "aw", "account", "limit"], "B_body": "This patch aims to resolve a lingering issue with Security Group Rules, \nwhere different resources generate rules that are consolidated on Amazon's \nside, as a result resulting in loss of local resources in the state file \nand duplication errors on AWS's side. \n\nExample:\n\n```\nresource \"aws_security_group_rule\" \"first\" {\n \u00a0 \u00a0type \u00a0 \u00a0 \u00a0 \u00a0= \"ingress\"\n \u00a0 \u00a0from_port \u00a0 = 80\n \u00a0 \u00a0to_port \u00a0 \u00a0 = 80\n \u00a0 \u00a0protocol \u00a0 \u00a0= \"tcp\"\n \u00a0 \u00a0cidr_blocks = [\"10.0.2.0/24\", \"10.0.3.0/24\"]\n\n \u00a0 security_group_id = \"${aws_security_group.nat.id}\"\n}\n```\n\nAfter applying this rule, our security group `nat` looks like this:\n\n```\n{\n  Description: \"Managed by Terraform\",\n  GroupId: \"sg-87eb46e3\",\n  GroupName: \"secg-nat\",\n  IpPermissions: [{\n      FromPort: 80,\n      IpProtocol: \"tcp\",\n      IpRanges: [{\n          CidrIp: \"10.0.2.0/24\"\n        },{\n          CidrIp: \"10.0.3.0/24\"\n        }],\n      ToPort: 80\n    }],\n  OwnerId: \"470663696735\",\n  VpcId: \"vpc-0806716d\"\n}\n```\n\nThis rule, with 2 `cidr_block` entires, is a single IPPermission rule according to the API.\n\nAt present, the Security Group Rule resource hashes it's values (ports, cidrs, security groups) \nto generate a key. This breaks down however, when another rule is added with a new `cidr_block`. \n\nNow, adding a second rule that also uses a `cidr_block` like so, will reveal the bug:\n\n```\nresource \"aws_security_group_rule\" \"second\" {\n \u00a0 \u00a0type \u00a0 \u00a0 \u00a0 \u00a0= \"ingress\"\n \u00a0 \u00a0from_port \u00a0 = 80\n \u00a0 \u00a0to_port \u00a0 \u00a0 = 80\n \u00a0 \u00a0protocol \u00a0 \u00a0= \"tcp\"\n \u00a0 \u00a0cidr_blocks = [\"10.0.5.0/24\"]\n\n \u00a0 security_group_id = \"${aws_security_group.nat.id}\"\n}\n```\n\nThe IPPermissions now look like this:\n\n```\nFull Security Group: {\n  Description: \"Managed by Terraform\",\n  GroupId: \"sg-87eb46e3\",\n  GroupName: \"secg-nat\",\n  IpPermissions: [{\n      FromPort: 80,\n      IpProtocol: \"tcp\",\n      IpRanges: [{\n          CidrIp: \"10.0.2.0/24\"\n        },{\n          CidrIp: \"10.0.3.0/24\"\n        },{\n          CidrIp: \"10.0.5.0/24\"\n        }],\n      ToPort: 80\n    }],\n  OwnerId: \"470663696735\",\n  VpcId: \"vpc-0806716d\"\n}\n```\n\nThe API has consolidated this new `cidr_block` into an existing rule, based on the port and \nprotocol it applies to. Because of the way Terraform hashes the rules locally, it can no longer find \neither resource, as it hashes the **entire IPPermission** looking for a match.\n\nThis pull request resolves this by iterating through `IpPermissions` and looking for matching criteria, \nensuring that each `cidr_block` or `security_group_id` is found in a set. \n\nThis patch also fixes another issue, where similar rules applied to different security groups caused the \nsame kind of conflict, because we were not hashing the security group id itself into the id of the rule. \nWe now consider the id in the hash for the rule to avoid this. \n\nRefs:\n- https://github.com/hashicorp/terraform/issues/2584#issuecomment-120088474\n- https://github.com/hashicorp/terraform/issues/2837\n- https://github.com/hashicorp/terraform/issues/2463\n", "B_clean_body": ["thi", "patch", "aim", "resolv", "linger", "issu", "secur", "group", "rule", "where", "differ", "resourc", "gener", "rule", "that", "are", "consolid", "amazon", "'s", "side", "as", "result", "result", "loss", "local", "resourc", "state", "file", "duplic", "error", "aw", "'s", "side", "exampl", "resourc", "aw", "secur", "group", "rule", "first", "type", "ingress", "port", "80", "port", "80", "protocol", "tcp", "cidr", "block", "10", "24", "10", "24", "secur", "group", "id", "nat", "id", "aw", "secur", "group", "after", "appli", "thi", "rule", "our", "secur", "group", "nat", "look", "like", "thi", "descript", "manag", "by", "terraform", "groupid", "group", "id", "sg", "87eb46e3", "groupnam", "group", "name", "secg", "nat", "ippermiss", "ip", "permiss", "fromport", "port", "80", "ipprotocol", "ip", "protocol", "tcp", "iprang", "ip", "rang", "cidrip", "cidr", "ip", "10", "24", "cidrip", "cidr", "ip", "10", "24", "toport", "port", "80", "ownerid", "owner", "id", "470663696735", "vpcid", "vpc", "id", "vpc", "0806716d", "thi", "rule", "cidr", "block", "entir", "singl", "ippermiss", "ip", "permiss", "rule", "accord", "api", "at", "present", "secur", "group", "rule", "resourc", "hash", "it", "'s", "valu", "port", "cidr", "secur", "group", "gener", "key", "thi", "break", "down", "howev", "when", "anoth", "rule", "ad", "new", "cidr", "block", "now", "ad", "second", "rule", "that", "also", "use", "cidr", "block", "like", "so", "will", "reveal", "bug", "resourc", "aw", "secur", "group", "rule", "second", "type", "ingress", "port", "80", "port", "80", "protocol", "tcp", "cidr", "block", "10", "24", "secur", "group", "id", "nat", "id", "aw", "secur", "group", "ippermiss", "ip", "permiss", "now", "look", "like", "thi", "full", "secur", "group", "descript", "manag", "by", "terraform", "groupid", "group", "id", "sg", "87eb46e3", "groupnam", "group", "name", "secg", "nat", "ippermiss", "ip", "permiss", "fromport", "port", "80", "ipprotocol", "ip", "protocol", "tcp", "iprang", "ip", "rang", "cidrip", "cidr", "ip", "10", "24", "cidrip", "cidr", "ip", "10", "24", "cidrip", "cidr", "ip", "10", "24", "toport", "port", "80", "ownerid", "owner", "id", "470663696735", "vpcid", "vpc", "id", "vpc", "0806716d", "api", "ha", "consolid", "thi", "new", "cidr", "block", "into", "exist", "rule", "base", "port", "protocol", "it", "appli", "becaus", "way", "terraform", "hash", "rule", "local", "it", "no", "longer", "find", "either", "resourc", "as", "it", "hash", "**entir", "ippermission**", "ip", "permission**", "look", "match", "thi", "pull", "request", "resolv", "thi", "by", "iter", "through", "ippermiss", "ip", "permiss", "look", "match", "criteria", "ensur", "that", "each", "cidr", "block", "or", "secur", "group", "id", "found", "set", "thi", "patch", "also", "fix", "anoth", "issu", "where", "similar", "rule", "appli", "differ", "secur", "group", "caus", "same", "kind", "conflict", "becaus", "we", "were", "not", "hash", "secur", "group", "id", "itself", "into", "id", "rule", "we", "now", "consid", "id", "hash", "rule", "avoid", "thi", "ref", "http", "github", "com", "hashicorp", "terraform", "issu", "2584", "issuecom", "120088474", "http", "github", "com", "hashicorp", "terraform", "issu", "2837", "http", "github", "com", "hashicorp", "terraform", "issu", "2463"], "title_sim": [0.6682481898280554], "body_sim": [0.40324797162763854], "file_list_sim": 1.0, "overlap_files_len": 4, "code_sim": [0.9976867703830604, 0.9976867703830604], "location_sim": [0.9930693069306931, 0.9930693069306931], "pattern": 0, "time": 5}, {"A_title": "Use a set for service account scopes.  Fix #1759", "A_clean_title": ["use", "set", "servic", "account", "scope", "fix", "1759"], "B_title": "provider/gce: Convert instance scopes to TypeSet", "B_clean_title": ["provid", "gce", "convert", "instanc", "scope", "typeset", "type", "set"], "A_body": "", "A_clean_body": [], "B_body": "#### provider/gce: Convert instance scopes to TypeSet\n\nThe GCE API (or library) always returns service account scopes in a\npre-defined order. So if you specify the following config:\n\n```\nservice_account {\n  scopes = [\n    \"userinfo-email\",\n    \"compute-ro\",\n    \"storage-ro\",\n  ]\n}\n```\n\nYou will get the following change on every apply:\n\n```\nservice_account.0.scopes.0:                 \"https://www.googleapis.com/auth/compute.readonly\" => \"https://www.googleapis.com/auth/userinfo.email\" (forces new resource)\nservice_account.0.scopes.1:                 \"https://www.googleapis.com/auth/devstorage.read_only\" => \"https://www.googleapis.com/auth/compute.readonly\" (forces new resource)\nservice_account.0.scopes.2:                 \"https://www.googleapis.com/auth/userinfo.email\" => \"https://www.googleapis.com/auth/devstorage.read_only\" (forces new resource)\n```\n\nFix this by converting scopes from `TypeList` to `TypeSet`. This ensures that\nwe have the correct entries by ignores the order that they appear in.\n#### provider/gce: Acceptance test for service_account\n\nAdd a new acceptance test for `google_compute_instance.service_account`\nwhich will confirm the change I'm about to make, to convert it from\n`TypeList` to `TypeSet`, will work. Since I already broke it during my\nmanual testing.\n\nThis didn't seem related to any of the existing tests so I've created a new\none. Although this will increase the runtime of the acceptance test suite.\n\nI also can't see that any of the existing tests do comparisons of sets, e.g.\nmaking sure that there aren't more tags or disk than we have specified. So I\nhave stuck with this convention and am just testing for the scopes that have\nbeen specified.\n\nThe exception to this is the number of `ServiceAccounts` entries. We\ncurrently only support one, so we can error if we have more or less than\nthis number.\n\n---\n\nThings I'm unsure about:\n- is a separate acceptance test OK?\n- should the test be more thorough?\n- should it test that it's idempotent on the second run? Is that possible? \n- I assume this doesn't need a state file migration?\n", "B_clean_body": ["provid", "gce", "convert", "instanc", "scope", "typeset", "type", "set", "gce", "api", "or", "librari", "alway", "return", "servic", "account", "scope", "pre", "defin", "order", "so", "you", "specifi", "follow", "config", "servic", "account", "scope", "userinfo", "email", "comput", "ro", "storag", "ro", "you", "will", "get", "follow", "chang", "everi", "appli", "scope", "servic", "account", "http", "googleapi", "readonli", "www", "com", "auth", "comput", "http", "googleapi", "email", "www", "com", "auth", "userinfo", "forc", "new", "resourc", "scope", "servic", "account", "http", "googleapi", "www", "com", "auth", "devstorag", "read", "onli", "http", "googleapi", "readonli", "www", "com", "auth", "comput", "forc", "new", "resourc", "scope", "servic", "account", "http", "googleapi", "email", "www", "com", "auth", "userinfo", "http", "googleapi", "www", "com", "auth", "devstorag", "read", "onli", "forc", "new", "resourc", "fix", "thi", "by", "convert", "scope", "typelist", "type", "list", "typeset", "type", "set", "thi", "ensur", "that", "we", "have", "correct", "entri", "by", "ignor", "order", "that", "they", "appear", "provid", "gce", "accept", "test", "servic", "account", "add", "new", "accept", "test", "googl", "comput", "instanc", "servic", "account", "which", "will", "confirm", "chang", "'m", "about", "make", "convert", "it", "typelist", "type", "list", "typeset", "type", "set", "will", "work", "sinc", "alreadi", "broke", "it", "dure", "my", "manual", "test", "thi", "did", "n't", "seem", "relat", "ani", "exist", "test", "so", "'ve", "creat", "new", "one", "although", "thi", "will", "increas", "runtim", "accept", "test", "suit", "also", "ca", "n't", "see", "that", "ani", "exist", "test", "comparison", "set", "make", "sure", "that", "there", "are", "n't", "more", "tag", "or", "disk", "than", "we", "have", "specifi", "so", "have", "stuck", "thi", "convent", "am", "just", "test", "scope", "that", "have", "been", "specifi", "except", "thi", "number", "serviceaccount", "servic", "account", "entri", "we", "current", "onli", "support", "one", "so", "we", "error", "we", "have", "more", "or", "less", "than", "thi", "number", "thing", "'m", "unsur", "about", "separ", "accept", "test", "ok", "test", "more", "thorough", "it", "test", "that", "it", "'s", "idempot", "second", "run", "that", "possibl", "assum", "thi", "n't", "need", "state", "file", "migrat"], "title_sim": [0.2584181824300887], "body_sim": [0.0], "file_list_sim": 0.5, "overlap_files_len": 2, "code_sim": [0.8048857098749393, 0.9944533030789393], "location_sim": [0.5537190082644629, 0.8007968127490039], "pattern": 0, "time": 3}, {"A_title": "providers/aws: resource aws_route53_zone_association", "A_clean_title": ["provid", "aw", "resourc", "aw", "route53", "zone", "associ"], "B_title": "AWS/Route53Zone - create private hosted zone associated with VPC.", "B_clean_title": ["aw", "route53zon", "creat", "privat", "host", "zone", "associ", "vpc"], "A_body": "wip adding `aws_route53_zone_association` as\n\n```\nresource \"aws_route53_zone_association\" \"foobar\" {\n    vpc_id  = \"foo\"\n    zone_id = \"bar\"\n    region  = \"us-west-2\"\n}\n```\n", "A_clean_body": ["wip", "ad", "aw", "route53", "zone", "associ", "as", "resourc", "aw", "route53", "zone", "associ", "foobar", "vpc", "id", "foo", "zone", "id", "bar", "region", "us", "west"], "B_body": "Add ability to create a private Hosted Zone that is associated to a VPC. \nCurrently only supports a single VPC at creation time. \n\nFuture question is how to support multiple VPCs. Amazon uses a Associate/Disassociate request, however this is problematic since you must specify one (and only one) VPC during creation.\n\nAlternatively, we could model it as a VPC Set and and use the first entry as the entry for creating and then associate the others.\n", "B_clean_body": ["add", "abil", "creat", "privat", "host", "zone", "that", "associ", "vpc", "current", "onli", "support", "singl", "vpc", "at", "creation", "time", "futur", "question", "how", "support", "multipl", "vpc", "vp", "cs", "amazon", "use", "associ", "disassoci", "request", "howev", "thi", "problemat", "sinc", "you", "must", "specifi", "one", "onli", "one", "vpc", "dure", "creation", "altern", "we", "could", "model", "it", "as", "vpc", "set", "use", "first", "entri", "as", "entri", "creat", "then", "associ", "other"], "title_sim": [0.37051734096451094], "body_sim": [0.0740249880388039], "file_list_sim": 0.6666666666666666, "overlap_files_len": 6, "code_sim": [0.9802346190600079, 0.9763000758800263], "location_sim": [0.7878513145965549, 0.8478048780487805], "pattern": 0, "time": 21}, {"A_title": "Documentation Update: Fix a code sample that uses incorrect syntax.", "A_clean_title": ["document", "updat", "fix", "code", "sampl", "that", "use", "incorrect", "syntax"], "B_title": "Update environments.html.md", "B_clean_title": ["updat", "environ", "html", "md"], "A_body": "## Reasoning for docs update\r\n\r\n`terraform env create` is not the correct syntax and its usage results in an error.\r\n\r\n## Relevant Terraform version\r\n\r\nI found this error when using the released`0.9.0`, and it appears in the `master` branch.", "A_clean_body": ["reason", "doc", "updat", "terraform", "env", "creat", "not", "correct", "syntax", "it", "usag", "result", "error", "relev", "terraform", "version", "found", "thi", "error", "when", "releas", "it", "appear", "master", "branch"], "B_body": "kind of confusing, example right below is different than quoted command.", "B_clean_body": ["kind", "confus", "exampl", "right", "below", "differ", "than", "quot", "command"], "title_sim": [0.18983113508351102], "body_sim": [0.037893288519670526], "file_list_sim": 1.0, "overlap_files_len": 1, "code_sim": [0.0, 0.0], "location_sim": [1.0, 1.0], "pattern": 0, "time": 1}, {"A_title": "provider/aws: fix EIPs on new upstream sdk", "A_clean_title": ["provid", "aw", "fix", "eip", "ei", "ps", "new", "upstream", "sdk"], "B_title": "provider/aws: Fix issue with updating VPC Security Group IDs for an Instance", "B_clean_title": ["provid", "aw", "fix", "issu", "updat", "vpc", "secur", "group", "id", "ds", "instanc"], "A_body": "As we've seen elsewhere, the SDK now wants nils instead of empty arrays\nfor collections\n\nfixes #1696\n\nthanks @jstremick for pointing me in the right direction\n", "A_clean_body": ["as", "we", "'ve", "seen", "elsewher", "sdk", "now", "want", "nil", "instead", "empti", "array", "collect", "fix", "1696", "thank", "jstremick", "point", "me", "right", "direct"], "B_body": "Currently, we aren't correctly setting the ids, and are setting both\n`security_groups` and `vpc_security_group_ids` in the state. As a result, we really only use\nthe former, but the latter never goes away in the state file :frowning: \n\nWe also don't actually update the remote security groups in the `update` method.\n\nThis PR fixes both issues, correctly reading `security_groups` vs.\n`vpc_security_group_ids` and allows users to update the latter without\ndestroying the Instance when in a VPC.\n\nShould fix #1611\n", "B_clean_body": ["current", "we", "are", "n't", "correctli", "set", "id", "are", "set", "both", "secur", "group", "vpc", "secur", "group", "id", "state", "as", "result", "we", "realli", "onli", "use", "former", "but", "latter", "never", "goe", "away", "state", "file", "frown", "we", "also", "n't", "actual", "updat", "remot", "secur", "group", "updat", "method", "thi", "pr", "fix", "both", "issu", "correctli", "read", "secur", "group", "vs", "vpc", "secur", "group", "id", "allow", "user", "updat", "latter", "without", "destroy", "instanc", "when", "vpc", "fix", "1611"], "title_sim": [0.5440622321542049], "body_sim": [0.2079257181161116], "file_list_sim": 0.0, "overlap_files_len": 0, "code_sim": [0.017512408705570862, 0.0], "location_sim": [0.0, 0.0], "pattern": -1, "time": 6}, {"A_title": "Allow a codepipeline action to specify a role_arn", "A_clean_title": ["allow", "codepipelin", "action", "specifi", "role", "arn"], "B_title": "Propagate AWS CodePipeline action roles", "B_clean_title": ["propag", "aw", "codepipelin", "code", "pipelin", "action", "role"], "A_body": "The codepipeline resource allows an action to specify a role_arn. However that role is never passed to AWS. This PR fixes that behavior.", "A_clean_body": ["codepipelin", "resourc", "allow", "action", "specifi", "role", "arn", "howev", "that", "role", "never", "pass", "aw", "thi", "pr", "fix", "that", "behavior"], "B_body": "CodePipeline stage actions can optionally specify an IAM execution role. The provider nominally supports them, but they don't seem to be getting passed to/from AWS.\r\n\r\n(Please forgive any non-idiomatic Go syntax. It is not in my wheelhouse.)", "B_clean_body": ["codepipelin", "code", "pipelin", "stage", "action", "option", "specifi", "iam", "execut", "role", "provid", "nomin", "support", "them", "but", "they", "n't", "seem", "get", "pass", "aw", "pleas", "forgiv", "ani", "non", "idiomat", "go", "syntax", "it", "not", "my", "wheelhous"], "title_sim": [0.6785048530556619], "body_sim": [0.4853638887427475], "file_list_sim": 1.0, "overlap_files_len": 2, "code_sim": [0.8208735464433743, 0.8208735464433743], "location_sim": [0.13468013468013468, 0.13468013468013468], "pattern": 0, "time": 6}, {"A_title": "provider/docker: locate container via ID not name", "A_clean_title": ["provid", "docker", "locat", "contain", "via", "id", "not", "name"], "B_title": "Fixed bug where docker_container resource was not working properly with swarm", "B_clean_title": ["fix", "bug", "where", "docker", "contain", "resourc", "wa", "not", "work", "properli", "swarm"], "A_body": "This reapplies the patch mentioned in #3364 - for an unknown reason the diff there was incorrect.\n\nAcceptance test run after applying this:\n\n```\n$ make testacc TEST=./builtin/providers/docker 2>&1 | tee /tmp/testrun.log | grep -E 'PASS|FAIL'\n--- PASS: TestProvider (0.00s)\n--- PASS: TestProvider_impl (0.00s)\n--- PASS: TestAccDockerContainer_basic (2.00s)\n--- PASS: TestAccDockerContainer_customized (1.86s)\n--- PASS: TestAccDockerImage_basic (1.67s)\n--- PASS: TestAddDockerImage_private (10.86s)\nPASS\n```\n", "A_clean_body": ["thi", "reappli", "patch", "mention", "3364", "unknown", "reason", "diff", "there", "wa", "incorrect", "accept", "test", "run", "after", "appli", "thi", "make", "testacc", "test=", "builtin", "provid", "docker", "tee", "log", "tmp", "testrun", "grep", "'pass|fail'", "pass", "testprovid", "test", "provid", "00", "pass", "testprovid", "impl", "test", "provid", "00", "pass", "testaccdockercontain", "basic", "test", "acc", "docker", "contain", "00", "pass", "testaccdockercontain", "custom", "test", "acc", "docker", "contain", "86", "pass", "testaccdockerimag", "basic", "test", "acc", "docker", "imag", "67", "pass", "testadddockerimag", "privat", "test", "add", "docker", "imag", "10", "86", "pass"], "B_body": "The docker_container resource was failing to work with Swarm as it was using the container name to test if it had started on a Swarm cluster. As Swarm prepends the hostname to a container name, this was failing. I have modified fetchDockerContainer to use the container's sha rather than it's name to test that it is still running.\n", "B_clean_body": ["docker", "contain", "resourc", "wa", "fail", "work", "swarm", "as", "it", "wa", "contain", "name", "test", "it", "had", "start", "swarm", "cluster", "as", "swarm", "prepend", "hostnam", "contain", "name", "thi", "wa", "fail", "have", "modifi", "fetchdockercontain", "fetch", "docker", "contain", "use", "contain", "'s", "sha", "rather", "than", "it", "'s", "name", "test", "that", "it", "still", "run"], "title_sim": [0.3929951533886944], "body_sim": [0.48840304777615906], "file_list_sim": 1.0, "overlap_files_len": 1, "code_sim": [1.0, 1.0], "location_sim": [0.21052631578947367, 0.21052631578947367], "pattern": 0, "time": 200}, {"A_title": "Allow importing of aws_iam_role, aws_iam_role_policy, aws_iam_policy and aws_iam_instance_profile.", "A_clean_title": ["allow", "import", "aw", "iam", "role", "aw", "iam", "role", "polici", "aw", "iam", "polici", "aw", "iam", "instanc", "profil"], "B_title": "provider/aws: Added the ability to import aws_iam_role's", "B_clean_title": ["provid", "aw", "ad", "abil", "import", "aw", "iam", "role", "'s"], "A_body": "", "A_clean_body": [], "B_body": "Not much to it, needed this to build a tf configuration for our core configs.\n", "B_clean_body": ["not", "much", "it", "need", "thi", "build", "tf", "configur", "our", "core", "config"], "title_sim": [0.8605186060905727], "body_sim": [0.0], "file_list_sim": 0.21428571428571427, "overlap_files_len": 3, "code_sim": [0.8543059628501186, 0.9658510775912424], "location_sim": [0.2706270627062706, 0.8677248677248677], "pattern": 0, "time": 96}, {"A_title": "provider/aws: Manage IAM policy documents", "A_clean_title": ["provid", "aw", "manag", "iam", "polici", "document"], "B_title": "Make aws_iam_role resource update assume_role_policy on diff.", "B_clean_title": ["make", "aw", "iam", "role", "resourc", "updat", "assum", "role", "polici", "diff"], "A_body": "This fixes #5201.\n\nThe `aws_iam_role` and `aws_iam_policy` resources don't manage policy documents because the resource never updates the policy after initial creation.\n#5201 pertains to `aws_iam_policy`. This change aims to apply the same fix to `aws_iam_role`.\n\nI have chosen to perform a more functional comparison by \"normalizing\" the policy documents by sorting keys and removing whitespace and newline characters. I have used `encoding/json` functions to perform that work.\n", "A_clean_body": ["thi", "fix", "5201", "aw", "iam", "role", "aw", "iam", "polici", "resourc", "n't", "manag", "polici", "document", "becaus", "resourc", "never", "updat", "polici", "after", "initi", "creation", "5201", "pertain", "aw", "iam", "polici", "thi", "chang", "aim", "appli", "same", "fix", "aw", "iam", "role", "have", "chosen", "perform", "more", "function", "comparison", "by", "normal", "polici", "document", "by", "sort", "key", "remov", "whitespac", "newlin", "charact", "have", "use", "encod", "json", "function", "perform", "that", "work"], "B_body": "Currently, Terraform does not pick up changes to the assume role policy.\n\nOne issue we found while writing these tests is that TestAccAWSRole_basic\ncurrently fails for us on master because AWS returns a differently formatted\npolicy document than Terraform is expecting so it fails the step because there\nis still a diff while planning.\n\nWe weren't sure if this is something specific to our AWS account, or if an\nunderlying change caused this dirty plan issue to start occurring. We can\nsubmit another PR to update the remaining policy docs if it is the latter.\n\nSigned-off-by: Michael Nussbaum michael.nussbaum@getbraintree.com\n", "B_clean_body": ["current", "terraform", "not", "pick", "up", "chang", "assum", "role", "polici", "one", "issu", "we", "found", "while", "write", "these", "test", "that", "testaccawsrol", "basic", "test", "acc", "aw", "role", "current", "fail", "us", "master", "becaus", "aw", "return", "differ", "format", "polici", "document", "than", "terraform", "expect", "so", "it", "fail", "step", "becaus", "there", "still", "diff", "while", "plan", "we", "were", "n't", "sure", "thi", "someth", "specif", "our", "aw", "account", "or", "underli", "chang", "caus", "thi", "dirti", "plan", "issu", "start", "occur", "we", "submit", "anoth", "pr", "updat", "remain", "polici", "doc", "it", "latter", "sign", "off", "by", "michael", "nussbaum", "michael", "nussbaum", "getbraintre", "com"], "title_sim": [0.22578554394070716], "body_sim": [0.6298225271149523], "file_list_sim": 0.25, "overlap_files_len": 1, "code_sim": [0.5766362600762481, 0.8825592269226974], "location_sim": [0.14381270903010032, 0.8269230769230769], "pattern": 0, "time": 0}, {"A_title": "Initial SNS topic / subscription support", "A_clean_title": ["initi", "sn", "topic", "subscript", "support"], "B_title": "Add support for SNS topics", "B_clean_title": ["add", "support", "sn", "topic"], "A_body": "Initial SNS topic and subscription support \n", "A_clean_body": ["initi", "sn", "topic", "subscript", "support"], "B_body": "Chips away at #28. This would have been the simplest thing in the world to do were it not for one, uh, feature of the SNS API. There is no way to describe or filter for an individual topic.\n\nInstead, you have to page results back from a complete topic list, and unlike autoscaling groups (whose paging limit is something like 1600), the paging limit for SNS topics is 100. I didn't feel right not supporting result paging here; it's entirely possible a TF user could have more than 100 SNS topics if they really love the product, so I wrote a pager.\n\nThe file is `sns_topic_seeker.go` and implements a basic state machine whose design will look mighty familiar if you've ever seen [this presentation](http://cuddle.googlecode.com/hg/talk/lex.html#title-slide) by Rob Pike or read the source code to `text/template/parse/lex.go` in the stdlib. It's basically a slimmed down implementation of the same pattern, and I've covered it with a bunch of unit tests to make sure it works and works well.\n\nFor what it's worth, I think it could be abstracted to an interface and used to \"page\" anything in AWS that returns a `NextToken`, but I didn't want to build a generalized version if this is the only AWS resource that'll use it.\n\nAnyway, let me know if there are any problems here. I'm going to add SNS topic support to AS groups too per #1419, but that file's a bit complex and I didn't feel like biting it off quite yet. I need it though so I'll try to finish it off later this week.\n", "B_clean_body": ["chip", "away", "at", "28", "thi", "would", "have", "been", "simplest", "thing", "world", "were", "it", "not", "one", "uh", "featur", "sn", "api", "there", "no", "way", "describ", "or", "filter", "individu", "topic", "instead", "you", "have", "page", "result", "back", "complet", "topic", "list", "unlik", "autosc", "group", "whose", "page", "limit", "someth", "like", "1600", "page", "limit", "sn", "topic", "100", "did", "n't", "feel", "right", "not", "support", "result", "page", "here", "it", "'s", "entir", "possibl", "tf", "user", "could", "have", "more", "than", "100", "sn", "topic", "they", "realli", "love", "product", "so", "wrote", "pager", "file", "go", "sn", "topic", "seeker", "implement", "basic", "state", "machin", "whose", "design", "will", "look", "mighti", "familiar", "you", "'ve", "ever", "seen", "thi", "present", "http", "googlecod", "html", "cuddl", "com", "hg", "talk", "lex", "titl", "slide", "by", "rob", "pike", "or", "read", "sourc", "code", "go", "text", "templat", "pars", "lex", "stdlib", "it", "'s", "basic", "slim", "down", "implement", "same", "pattern", "'ve", "cover", "it", "bunch", "unit", "test", "make", "sure", "it", "work", "work", "well", "what", "it", "'s", "worth", "think", "it", "could", "abstract", "interfac", "use", "page", "anyth", "aw", "that", "return", "nexttoken", "next", "token", "but", "did", "n't", "want", "build", "gener", "version", "thi", "onli", "aw", "resourc", "that", "'ll", "use", "it", "anyway", "let", "me", "know", "there", "are", "ani", "problem", "here", "'m", "go", "add", "sn", "topic", "support", "as", "group", "too", "per", "1419", "but", "that", "file", "'s", "bit", "complex", "did", "n't", "feel", "like", "bite", "it", "off", "quit", "yet", "need", "it", "though", "so", "'ll", "tri", "finish", "it", "off", "later", "thi", "week"], "title_sim": [0.7295974083468165], "body_sim": [0.1071097334041943], "file_list_sim": 0.46153846153846156, "overlap_files_len": 6, "code_sim": [0.8243915033075491, 0.9379972302939042], "location_sim": [0.4349561053471668, 0.9284497444633731], "pattern": 0, "time": 1}, {"A_title": "S3 Bucket Object Sever Side Encryption", "A_clean_title": ["s3", "bucket", "object", "sever", "side", "encrypt"], "B_title": "provider/aws: Support S3 bucket object upload with AES256 server-side encryption", "B_clean_title": ["provid", "aw", "support", "s3", "bucket", "object", "upload", "aes256", "server", "side", "encrypt"], "A_body": "This PR sees support for server side encryption added to s3 bucket object resources. This functionality is equivalent to\r\n\r\n```\r\naws s3 cp --sse aws:kms source destination\r\n```\r\n\r\nwhich facilitates using S3 default master key for server side encryption.\r\n\r\n Associated acceptance testing and documentation has been included.", "A_clean_body": ["thi", "pr", "see", "support", "server", "side", "encrypt", "ad", "s3", "bucket", "object", "resourc", "thi", "function", "equival", "aw", "s3", "cp", "sse", "aw", "km", "sourc", "destin", "which", "facilit", "s3", "default", "master", "key", "server", "side", "encrypt", "associ", "accept", "test", "document", "ha", "been", "includ"], "B_body": "- Add optional aws_s3_bucket_object boolean `encrypt` attribute to allow AES256 server-side encryption modeled after the [S3 Remote State Backend](https://www.terraform.io/docs/state/remote/s3.html)\n- If `encrypt = true` and no AWS KMS Key ID is specified then a server-side encryption value of **AES256** is used\n- Setting a value for `kms_key_id` implicitly sets `encrypt = true`\n- Update documentation\n- Add new acceptance test:\n\n```\n$ make testacc TEST=./builtin/providers/aws TESTARGS='-run=TestAccAWSS3BucketObject_sse_aes256' \n==> Checking that code complies with gofmt requirements...\ngo generate $(go list ./... | grep -v /terraform/vendor/)\n2016/10/19 17:48:36 Generated command/internal_plugin_list.go\nTF_ACC=1 go test ./builtin/providers/aws -v -run=TestAccAWSS3BucketObject_sse_aes256 -timeout 120m\n=== RUN   TestAccAWSS3BucketObject_sse_aes256\n--- PASS: TestAccAWSS3BucketObject_sse_aes256 (21.35s)\nPASS\nok      github.com/hashicorp/terraform/builtin/providers/aws    21.362s\n```\n- Verify no regression:\n\n```\n$ make testacc TEST=./builtin/providers/aws TESTARGS='-run=TestAccAWSS3BucketObject_kms' \n==> Checking that code complies with gofmt requirements...\ngo generate $(go list ./... | grep -v /terraform/vendor/)\n2016/10/19 17:47:31 Generated command/internal_plugin_list.go\nTF_ACC=1 go test ./builtin/providers/aws -v -run=TestAccAWSS3BucketObject_kms -timeout 120m\n=== RUN   TestAccAWSS3BucketObject_kms\n--- PASS: TestAccAWSS3BucketObject_kms (42.98s)\nPASS\nok      github.com/hashicorp/terraform/builtin/providers/aws    42.991s\n```\n", "B_clean_body": ["add", "option", "aw", "s3", "bucket", "object", "boolean", "encrypt", "attribut", "allow", "aes256", "server", "side", "encrypt", "model", "after", "s3", "remot", "state", "backend", "http", "terraform", "html", "www", "io", "doc", "state", "remot", "s3", "encrypt", "true", "no", "aw", "km", "key", "id", "specifi", "then", "server", "side", "encrypt", "valu", "**aes256**", "use", "set", "valu", "km", "key", "id", "implicitli", "set", "encrypt", "true", "updat", "document", "add", "new", "accept", "test", "make", "testacc", "test=", "builtin", "provid", "aw", "testargs='", "run=testaccawss3bucketobject", "sse", "aes256", "run=test", "acc", "awss3bucket", "object", "check", "that", "code", "compli", "gofmt", "requir", "go", "gener", "go", "list", "grep", "terraform", "vendor", "2016", "10", "19", "17:48:36", "gener", "go", "plugin", "list", "command", "intern", "tf", "acc=1", "go", "test", "builtin", "provid", "aw", "run=testaccawss3bucketobject", "sse", "aes256", "run=test", "acc", "awss3bucket", "object", "timeout", "120m", "run", "testaccawss3bucketobject", "sse", "aes256", "test", "acc", "awss3bucket", "object", "pass", "testaccawss3bucketobject", "sse", "aes256", "test", "acc", "awss3bucket", "object", "21", "35", "pass", "ok", "github", "com", "hashicorp", "terraform", "builtin", "provid", "aw", "21", "362", "verifi", "no", "regress", "make", "testacc", "test=", "builtin", "provid", "aw", "testargs='", "run=testaccawss3bucketobject", "km", "run=test", "acc", "awss3bucket", "object", "check", "that", "code", "compli", "gofmt", "requir", "go", "gener", "go", "list", "grep", "terraform", "vendor", "2016", "10", "19", "17:47:31", "gener", "go", "plugin", "list", "command", "intern", "tf", "acc=1", "go", "test", "builtin", "provid", "aw", "run=testaccawss3bucketobject", "km", "run=test", "acc", "awss3bucket", "object", "timeout", "120m", "run", "testaccawss3bucketobject", "km", "test", "acc", "awss3bucket", "object", "pass", "testaccawss3bucketobject", "km", "test", "acc", "awss3bucket", "object", "42", "98", "pass", "ok", "github", "com", "hashicorp", "terraform", "builtin", "provid", "aw", "42", "991"], "title_sim": [0.8062279861808861], "body_sim": [0.5903291388067672], "file_list_sim": 1.0, "overlap_files_len": 3, "code_sim": [0.7986057036134695, 0.7986057036134695], "location_sim": [0.6635802469135802, 0.6635802469135802], "pattern": 0, "time": 90}, {"A_title": "Expose Route53 zone nameservers for parent zone NS record", "A_clean_title": ["expos", "route53", "zone", "nameserv", "parent", "zone", "ns", "record"], "B_title": "provider/aws: expose Route 53 zone nameservers", "B_clean_title": ["provid", "aw", "expos", "rout", "53", "zone", "nameserv"], "A_body": "", "A_clean_body": [], "B_body": ":construction: \nThis PR attempts to expose the NS elements of Route 53 zone. Refs #462 \n", "B_clean_body": ["construct", "thi", "pr", "attempt", "expos", "ns", "element", "rout", "53", "zone", "ref", "462"], "title_sim": [0.09936369889261906], "body_sim": [0.0], "file_list_sim": 0.3333333333333333, "overlap_files_len": 1, "code_sim": [0.39731282718521715, 0.4272071477805695], "location_sim": [0.576, 0.8571428571428571], "pattern": 0, "time": 28}, {"A_title": "providers/google: Change account_file to expect a JSON string", "A_clean_title": ["provid", "googl", "chang", "account", "file", "expect", "json", "string"], "B_title": "google: Expand tilde in account_file path", "B_clean_title": ["googl", "expand", "tild", "account", "file", "path"], "A_body": "Using the Google provider from [Atlas](https://atlas.hashicorp.com) if currently not possible without committing the `account_file` to version control, or only using `terraform push`. This adds `account_file_contents` to allow specifying the contents of the `account_file` in an environment variable (encrypted on Atlas).\n", "A_clean_body": ["googl", "provid", "atla", "http", "hashicorp", "com", "atla", "current", "not", "possibl", "without", "commit", "account", "file", "version", "control", "or", "onli", "terraform", "push", "thi", "add", "account", "file", "content", "allow", "specifi", "content", "account", "file", "environ", "variabl", "encrypt", "atla"], "B_body": "This will allow the following:\n\n``` ruby\nprovider \"google\" {\n    project = \"yada-yada\"\n    region = \"us-central1\"\n    account_file = \"~/.gcloud/anything.json\"\n}\n```\n", "B_clean_body": ["thi", "will", "allow", "follow", "rubi", "provid", "googl", "project", "yada", "yada", "region", "us", "central1", "account", "file", "json", "gcloud", "anyth"], "title_sim": [0.504935573584774], "body_sim": [0.5501879501048507], "file_list_sim": 0.25, "overlap_files_len": 1, "code_sim": [0.2843949651768117, 0.2549279699424838], "location_sim": [0.3283582089552239, 0.8148148148148148], "pattern": 0, "time": 4}, {"A_title": "Small fix needed to be inline with the updated AWS SDK again...", "A_clean_title": ["small", "fix", "need", "inlin", "updat", "aw", "sdk", "again"], "B_title": "switch to updated aws-sdk-go credentials", "B_clean_title": ["switch", "updat", "aw", "sdk", "go", "credenti"], "A_body": "Executed a couple of AWS ACC test as well to make sure everything works properly again after this fix\u2026\n", "A_clean_body": ["execut", "coupl", "aw", "acc", "test", "as", "well", "make", "sure", "everyth", "work", "properli", "again", "after", "thi", "fix\u2026"], "B_body": "Seems aws-sdk-go has changed a bit..\n\n_rant_, golang dependency management (or lack thereof) sucks, should we vendor deps? \n", "B_clean_body": ["seem", "aw", "sdk", "go", "ha", "chang", "bit", "rant", "golang", "depend", "manag", "or", "lack", "thereof", "suck", "we", "vendor", "dep"], "title_sim": [0.6295673688475887], "body_sim": [0.22147220164910728], "file_list_sim": 1.0, "overlap_files_len": 3, "code_sim": [0.8087775670537389, 0.8087775670537389], "location_sim": [1.0, 1.0], "pattern": 0, "time": 0}, {"A_title": "provider/azurerm: support importing of subnet resource", "A_clean_title": ["provid", "azurerm", "support", "import", "subnet", "resourc"], "B_title": "provider/azurerm: Fixes for azurerm subnet properties", "B_clean_title": ["provid", "azurerm", "fix", "azurerm", "subnet", "properti"], "A_body": "```\nTF_ACC=1 go test ./builtin/providers/azurerm -v -run TestAccAzureRMSubnet -timeout 120m\n=== RUN   TestAccAzureRMSubnet_importBasic\n--- PASS: TestAccAzureRMSubnet_importBasic (165.04s)\n=== RUN   TestAccAzureRMSubnet_basic\n--- PASS: TestAccAzureRMSubnet_basic (165.39s)\n=== RUN   TestAccAzureRMSubnet_disappears\n--- PASS: TestAccAzureRMSubnet_disappears (170.02s)\nPASS\nok      github.com/hashicorp/terraform/builtin/providers/azurerm    500.533s\n```\n", "A_clean_body": ["tf", "acc=1", "go", "test", "builtin", "provid", "azurerm", "run", "testaccazurermsubnet", "test", "acc", "azur", "rm", "subnet", "timeout", "120m", "run", "testaccazurermsubnet", "importbas", "test", "acc", "azur", "rm", "subnet", "import", "basic", "pass", "testaccazurermsubnet", "importbas", "test", "acc", "azur", "rm", "subnet", "import", "basic", "165", "04", "run", "testaccazurermsubnet", "basic", "test", "acc", "azur", "rm", "subnet", "pass", "testaccazurermsubnet", "basic", "test", "acc", "azur", "rm", "subnet", "165", "39", "run", "testaccazurermsubnet", "disappear", "test", "acc", "azur", "rm", "subnet", "pass", "testaccazurermsubnet", "disappear", "test", "acc", "azur", "rm", "subnet", "170", "02", "pass", "ok", "github", "com", "hashicorp", "terraform", "builtin", "provid", "azurerm", "500", "533"], "B_body": "Partially fixes GH-8227\n\nSo far this implements the setting of address range, route table association and network security group association for azurerm subnet resource.\n\nThere is still failure when going from a set resource to none for route tables and nsg, e.g.\n\n```\nresource \"azurerm_subnet\" \"test\" {\n    name = \"testsubnet\"\n    resource_group_name = \"${azurerm_resource_group.test.name}\"\n    virtual_network_name = \"${azurerm_virtual_network.test.name}\"\n    address_prefix = \"10.0.1.0/24\"\n    route_table_id = \"${azurerm_route_table.test.id}\"\n    network_security_group_id = \"${azurerm_network_security_group.test.id}\"\n}\n```\n\nto \n\n```\nresource \"azurerm_subnet\" \"test\" {\n    name = \"testsubnet\"\n    resource_group_name = \"${azurerm_resource_group.test.name}\"\n    virtual_network_name = \"${azurerm_virtual_network.test.name}\"\n    address_prefix = \"10.0.1.0/24\"\n    route_table_id = \"\"\n    network_security_group_id = \"\"\n}\n```\n", "B_clean_body": ["partial", "fix", "gh", "8227", "so", "far", "thi", "implement", "set", "address", "rang", "rout", "tabl", "associ", "network", "secur", "group", "associ", "azurerm", "subnet", "resourc", "there", "still", "failur", "when", "go", "set", "resourc", "none", "rout", "tabl", "nsg", "resourc", "azurerm", "subnet", "test", "name", "testsubnet", "resourc", "group", "name", "test", "name", "azurerm", "resourc", "group", "virtual", "network", "name", "test", "name", "azurerm", "virtual", "network", "address", "prefix", "10", "24", "rout", "tabl", "id", "test", "id", "azurerm", "rout", "tabl", "network", "secur", "group", "id", "test", "id", "azurerm", "network", "secur", "group", "resourc", "azurerm", "subnet", "test", "name", "testsubnet", "resourc", "group", "name", "test", "name", "azurerm", "resourc", "group", "virtual", "network", "name", "test", "name", "azurerm", "virtual", "network", "address", "prefix", "10", "24", "rout", "tabl", "id", "network", "secur", "group", "id"], "title_sim": [0.7498248342244426], "body_sim": [0.4663691280080294], "file_list_sim": 0.25, "overlap_files_len": 1, "code_sim": [0.7981463446596246, 0.9183681548771974], "location_sim": [0.2222222222222222, 0.7058823529411765], "pattern": -1, "time": 44}, {"A_title": "Improve idempotency of aws_iam_server_certificate provisioning", "A_clean_title": ["improv", "idempot", "aw", "iam", "server", "certif", "provis"], "B_title": "provider/aws: Add IAM Server Certificate resource", "B_clean_title": ["provid", "aw", "add", "iam", "server", "certif", "resourc"], "A_body": "This pull request addresses issue #2409. A brief recap follows:\n\nWhen Terraform pulls down state data about AWS IAM certificates in its purview, it normalizes the certificate body by trimming whitespace from it and taking a SHA1 hash of the resulting string. This works well for dealing with newline characters at the end of a certificate, however, this logic does not apply to the certificate _chain_. A change to the certificate chain is enough for Terraform to rebuild the resource. The combination of these two circumstances means that, if one has an IAM certificate with a chain in their Terraform configuration, `terraform plan` will _always_ require some action, even if everything appears to be in sync.\n\nThis pull request normalizes the certificate chain in the same way as the certificate body. While the major gains are in the use of `strings.TrimSpace`, the SHA hashing is nice to have, as well. In passing, the integration test for this resource has been updated to include a self-signed certificate bearing a CA chain.\n", "A_clean_body": ["thi", "pull", "request", "address", "issu", "2409", "brief", "recap", "follow", "when", "terraform", "pull", "down", "state", "data", "about", "aw", "iam", "certif", "it", "purview", "it", "normal", "certif", "bodi", "by", "trim", "whitespac", "it", "take", "sha1", "hash", "result", "string", "thi", "work", "well", "deal", "newlin", "charact", "at", "end", "certif", "howev", "thi", "logic", "not", "appli", "certif", "chain", "chang", "certif", "chain", "enough", "terraform", "rebuild", "resourc", "combin", "these", "two", "circumst", "mean", "that", "one", "ha", "iam", "certif", "chain", "their", "terraform", "configur", "terraform", "plan", "will", "alway", "requir", "some", "action", "even", "everyth", "appear", "sync", "thi", "pull", "request", "normal", "certif", "chain", "same", "way", "as", "certif", "bodi", "while", "major", "gain", "are", "use", "string", "trimspac", "trim", "space", "sha", "hash", "nice", "have", "as", "well", "pass", "integr", "test", "thi", "resourc", "ha", "been", "updat", "includ", "self", "sign", "certif", "bear", "ca", "chain"], "B_body": "Adds a new AWS Resource, IAM Server Certificate:\n- http://docs.aws.amazon.com/IAM/latest/UserGuide/ManagingServerCerts.html#VerifyCertObject\n\nServer certs uploaded to IAM can be used in a few places:\n- AWS Elastic Beanstalk\n- Elastic Load Balancing\n- CloudFront\n- AWS OpsWorks\n\nAdding docs now, wanted to open for any thoughts from @phinze \n\nUPDATE: docs added, squashed\n", "B_clean_body": ["add", "new", "aw", "resourc", "iam", "server", "certif", "http", "aw", "amazon", "html", "doc", "com", "iam", "latest", "userguid", "managingservercert", "user", "guid", "manag", "server", "cert", "verifycertobject", "verifi", "cert", "object", "server", "cert", "upload", "iam", "use", "few", "place", "aw", "elast", "beanstalk", "elast", "load", "balanc", "cloudfront", "cloud", "front", "aw", "opswork", "op", "work", "ad", "doc", "now", "want", "open", "ani", "thought", "phinz", "updat", "doc", "ad", "squash"], "title_sim": [0.5817219130782505], "body_sim": [0.2430045394626182], "file_list_sim": 0.4, "overlap_files_len": 2, "code_sim": [0.07124995597306628, 0.07774069195493231], "location_sim": [0.7897526501766784, 1.0], "pattern": 0, "time": 25}, {"A_title": "provider/aws: Fix issue with LB Cookie Stickiness and empty expiration period", "A_clean_title": ["provid", "aw", "fix", "issu", "lb", "cooki", "sticki", "empti", "expir", "period"], "B_title": "provider/aws: Lb cookie stickiness", "B_clean_title": ["provid", "aw", "lb", "cooki", "sticki"], "A_body": "`cookie_expiration_period` is optional for the `aws_lb_cookie_stickiness_policy` resource, however we were sending the default value (`0`) if nothing was in the configuration, which is invalid.\n\nThe change in `resource_aws_lb_cookie_stickiness_policy_test` confirms the bug/fix \n\nFixes #3208 \n", "A_clean_body": ["cooki", "expir", "period", "option", "aw", "lb", "cooki", "sticki", "polici", "resourc", "howev", "we", "were", "send", "default", "valu", "noth", "wa", "configur", "which", "invalid", "chang", "resourc", "aw", "lb", "cooki", "sticki", "polici", "test", "confirm", "bug", "fix", "fix", "3208"], "B_body": "This is based off #2907 and incorporates the feedback from @radeksimko. Decided to open a PR for this because the issue has been inactive since Sept 19th\n\n//cc @radeksimko \n", "B_clean_body": ["thi", "base", "off", "2907", "incorpor", "feedback", "radeksimko", "decid", "open", "pr", "thi", "becaus", "issu", "ha", "been", "inact", "sinc", "sept", "19th", "cc", "radeksimko"], "title_sim": [0.6025094155220465], "body_sim": [0.03957797395573846], "file_list_sim": 0.5, "overlap_files_len": 1, "code_sim": [0.2116236466376718, 0.20948978318333664], "location_sim": [0.6486486486486487, 0.7058823529411765], "pattern": -1, "time": 1}, {"A_title": "command: Remove second DefaultDataDirectory const", "A_clean_title": ["command", "remov", "second", "defaultdatadirectori", "default", "data", "directori", "const"], "B_title": "Remove redundant const from command package", "B_clean_title": ["remov", "redund", "const", "command", "packag"], "A_body": "", "A_clean_body": [], "B_body": "Replace usages of DefaultDataDir with the equivalent DefaultDataDirectory\nRemove now unused DefaultDataDir const\n", "B_clean_body": ["replac", "usag", "defaultdatadir", "default", "data", "dir", "equival", "defaultdatadirectori", "default", "data", "directori", "remov", "now", "unus", "defaultdatadir", "default", "data", "dir", "const"], "title_sim": [0.27479406700608044], "body_sim": [0.0], "file_list_sim": 0.08333333333333333, "overlap_files_len": 1, "code_sim": [0.0, 0.0], "location_sim": [0.08383233532934131, 0.7], "pattern": 0, "time": 7}, {"A_title": "provider/aws: Add missing id argument for Route Table data source", "A_clean_title": ["provid", "aw", "add", "miss", "id", "argument", "rout", "tabl", "data", "sourc"], "B_title": "provider/aws: fix the datasource aws_route_table, support for id argument", "B_clean_title": ["provid", "aw", "fix", "datasourc", "aw", "rout", "tabl", "support", "id", "argument"], "A_body": "Documentation for the `aws_route_table` data source mentions that it supports a route table `id` as an argument, however it was missing from the actual provider code.\r\n\r\nAdds in the missing provider code, adds a test, and updates the documentation to use `rtb_id` as the argument, instead of the more ambiguous `id`.", "A_clean_body": ["document", "aw", "rout", "tabl", "data", "sourc", "mention", "that", "it", "support", "rout", "tabl", "id", "as", "argument", "howev", "it", "wa", "miss", "actual", "provid", "code", "add", "miss", "provid", "code", "add", "test", "updat", "document", "use", "rtb", "id", "as", "argument", "instead", "more", "ambigu", "id"], "B_body": "This PR implements the `id` argument in the datasource `aws_route_table`.\r\n\r\nBut I hava an issue in the tests:\r\n```\r\nvagrant@terraform:/opt/gopath/src/github.com/hashicorp/terraform$ TF_ACC=true go test  -v github.com/hashicorp/terraform/builtin/providers/aws -run ^TestAccDataSourceAwsRouteTable$\r\n=== RUN   TestAccDataSourceAwsRouteTable\r\n--- FAIL: TestAccDataSourceAwsRouteTable (25.74s)\r\n\ttesting.go:265: Step 0 error: After applying this step and refreshing, the plan was not empty:\r\n\r\n\t\tDIFF:\r\n\r\n\t\tUPDATE: data.aws_route_table.by_filter\r\n\t\t  associations.#:                    \"\" => \"<computed>\"\r\n\t\t  filter.#:                          \"0\" => \"1\"\r\n\t\t  filter.407483565.name:             \"\" => \"association.route-table-association-id\"\r\n\t\t  filter.407483565.values.#:         \"0\" => \"1\"\r\n\t\t  filter.407483565.values.187076141: \"\" => \"rtbassoc-91d286f9\"\r\n\t\t  routes.#:                          \"\" => \"<computed>\"\r\n\t\t  subnet_id:                         \"\" => \"<computed>\"\r\n\t\t  tags.%:                            \"\" => \"<computed>\"\r\n\t\t  vpc_id:                            \"\" => \"<computed>\"\r\n\t\tUPDATE: data.aws_route_table.by_id\r\n\t\t  associations.#: \"\" => \"<computed>\"\r\n\t\t  routes.#:       \"\" => \"<computed>\"\r\n\t\t  subnet_id:      \"\" => \"<computed>\"\r\n\t\t  tags.%:         \"\" => \"<computed>\"\r\n\t\t  vpc_id:         \"\" => \"<computed>\"\r\n\t\tUPDATE: data.aws_route_table.by_subnet\r\n\t\t  associations.#: \"\" => \"<computed>\"\r\n\t\t  routes.#:       \"\" => \"<computed>\"\r\n\t\t  subnet_id:      \"\" => \"subnet-de3be8a4\"\r\n\t\t  tags.%:         \"\" => \"<computed>\"\r\n\t\t  vpc_id:         \"\" => \"<computed>\"\r\n\t\tUPDATE: data.aws_route_table.by_tag\r\n\t\t  associations.#: \"\" => \"<computed>\"\r\n\t\t  routes.#:       \"\" => \"<computed>\"\r\n\t\t  subnet_id:      \"\" => \"<computed>\"\r\n\t\t  tags.%:         \"0\" => \"1\"\r\n\t\t  tags.Name:      \"\" => \"terraform-testacc-routetable-data-source\"\r\n\t\t  vpc_id:         \"\" => \"<computed>\"\r\n\r\n\t\tSTATE:\r\n\r\n\t\taws_route_table.test:\r\n\t\t  ID = rtb-c94bffa1\r\n\t\t  propagating_vgws.# = 0\r\n\t\t  route.# = 0\r\n\t\t  tags.% = 1\r\n\t\t  tags.Name = terraform-testacc-routetable-data-source\r\n\t\t  vpc_id = vpc-28965f40\r\n\r\n\t\t  Dependencies:\r\n\t\t    aws_vpc.test\r\n\t\taws_route_table_association.a:\r\n\t\t  ID = rtbassoc-91d286f9\r\n\t\t  route_table_id = rtb-c94bffa1\r\n\t\t  subnet_id = subnet-de3be8a4\r\n\r\n```\r\n\r\nCan you explain me how to fix this please ?\r\nThanks", "B_clean_body": ["thi", "pr", "implement", "id", "argument", "datasourc", "aw", "rout", "tabl", "but", "hava", "issu", "test", "vagrant", "terraform", "opt", "gopath", "src", "github", "com", "hashicorp", "terraform", "tf", "acc=tru", "go", "test", "github", "com", "hashicorp", "terraform", "builtin", "provid", "aw", "run", "^testaccdatasourceawsroutet", "^test", "acc", "data", "sourc", "aw", "rout", "tabl", "run", "testaccdatasourceawsroutet", "test", "acc", "data", "sourc", "aw", "rout", "tabl", "fail", "testaccdatasourceawsroutet", "test", "acc", "data", "sourc", "aw", "rout", "tabl", "25", "74", "test", "go:265", "step", "error", "after", "appli", "thi", "step", "refresh", "plan", "wa", "not", "empti", "diff", "updat", "data", "aw", "rout", "tabl", "by", "filter", "associ", "comput", "filter", "filter", "407483565", "name", "tabl", "associ", "id", "associ", "rout", "filter", "407483565", "valu", "filter", "407483565", "valu", "187076141", "rtbassoc", "91d286f9", "rout", "comput", "subnet", "id", "comput", "tag", "comput", "vpc", "id", "comput", "updat", "data", "aw", "rout", "tabl", "by", "id", "associ", "comput", "rout", "comput", "subnet", "id", "comput", "tag", "comput", "vpc", "id", "comput", "updat", "data", "aw", "rout", "tabl", "by", "subnet", "associ", "comput", "rout", "comput", "subnet", "id", "subnet", "de3be8a4", "tag", "comput", "vpc", "id", "comput", "updat", "data", "aw", "rout", "tabl", "by", "tag", "associ", "comput", "rout", "comput", "subnet", "id", "comput", "tag", "tag", "name", "terraform", "testacc", "routet", "data", "sourc", "vpc", "id", "comput", "state", "test", "aw", "rout", "tabl", "id", "rtb", "c94bffa1", "propag", "vgw", "rout", "tag", "tag", "name", "terraform", "testacc", "routet", "data", "sourc", "vpc", "id", "vpc", "28965f40", "depend", "test", "aw", "vpc", "aw", "rout", "tabl", "associ", "id", "rtbassoc", "91d286f9", "rout", "tabl", "id", "rtb", "c94bffa1", "subnet", "id", "subnet", "de3be8a4", "you", "explain", "me", "how", "fix", "thi", "pleas", "thank"], "title_sim": [0.7225504676847447], "body_sim": [0.5947687887983122], "file_list_sim": 0.6666666666666666, "overlap_files_len": 2, "code_sim": [0.9388948326460582, 0.9517901930330811], "location_sim": [0.6990291262135923, 0.75], "pattern": 0, "time": 21}, {"A_title": "provider alicloud:add new rds resource and some bugs fix", "A_clean_title": ["provid", "alicloud", "add", "new", "rd", "resourc", "some", "bug", "fix"], "B_title": "provider/alicloud: change create ecs postpaid instance API (#12226)", "B_clean_title": ["provid", "alicloud", "chang", "creat", "ec", "postpaid", "instanc", "api", "12226"], "A_body": "IMPROVEMENTS:\r\n\r\nalicloud/config: add businessinfo to sdk client [#96](https://github.com/alibaba/terraform-provider/pull/96)\r\n\r\nresource/alicloud_instance: change create ecs postpaid instance API form createInstance to runInstances, support BusinessInfo [#80](https://github.com/alibaba/terraform-provider/pull/80)\r\nresource/alicloud_instance: change ecs parameter zoneId from required to optional [#74](https://github.com/alibaba/terraform-provider/pull/74)\r\nresource/alicloud_instance: support userdata [#71](https://github.com/alibaba/terraform-provider/pull/71)\r\n\r\nBUG FIXES:\r\n\r\nresource/alicloud_db_instance: fix rds update failed bug [#102](https://github.com/alibaba/terraform-provider/pull/102)\r\nresource/alicloud_instance: fix ecs instance system disk size not work bug [#100](https://github.com/alibaba/terraform-provider/pull/100)", "A_clean_body": ["improv", "alicloud", "config", "add", "businessinfo", "sdk", "client", "96", "http", "provid", "pull", "96", "github", "com", "alibaba", "terraform", "instanc", "resourc", "alicloud", "chang", "creat", "ec", "postpaid", "instanc", "api", "form", "createinst", "creat", "instanc", "runinst", "run", "instanc", "support", "businessinfo", "busi", "info", "80", "http", "provid", "pull", "80", "github", "com", "alibaba", "terraform", "instanc", "resourc", "alicloud", "chang", "ec", "paramet", "zoneid", "zone", "id", "requir", "option", "74", "http", "provid", "pull", "74", "github", "com", "alibaba", "terraform", "instanc", "resourc", "alicloud", "support", "userdata", "71", "http", "provid", "pull", "71", "github", "com", "alibaba", "terraform", "bug", "fix", "db", "instanc", "resourc", "alicloud", "fix", "rd", "updat", "fail", "bug", "102", "http", "provid", "pull", "102", "github", "com", "alibaba", "terraform", "instanc", "resourc", "alicloud", "fix", "ec", "instanc", "system", "disk", "size", "not", "work", "bug", "100", "http", "provid", "pull", "100", "github", "com", "alibaba", "terraform"], "B_body": "* change create ecs postpaid instance API form createInstance to runInstances, support BusinessInfo and userdata\n\n* update sdk vendor", "B_clean_body": ["chang", "creat", "ec", "postpaid", "instanc", "api", "form", "createinst", "creat", "instanc", "runinst", "run", "instanc", "support", "businessinfo", "busi", "info", "userdata", "updat", "sdk", "vendor"], "title_sim": [0.20211210447353048], "body_sim": [0.5833438954522955], "file_list_sim": 0, "overlap_files_len": 0, "code_sim": [0.0, 0.0], "location_sim": [0.0, 0.0], "pattern": -1, "time": 0}, {"A_title": "provider/aws: Normalize and compact SQS Redrive, Policy JSON", "A_clean_title": ["provid", "aw", "normal", "compact", "sq", "redriv", "polici", "json"], "B_title": "AWS SQS policy normalization", "B_clean_title": ["aw", "sq", "polici", "normal"], "A_body": "The `redrive_policy` needs to be normalized on save to state, and we now document that the `maxReceiveCount` should be an integer, not a string. Unfortunately the AWS API accepts either, but will always return an integer. \n\nFixes #5119 \n", "A_clean_body": ["redriv", "polici", "need", "normal", "save", "state", "we", "now", "document", "that", "maxreceivecount", "max", "receiv", "count", "integ", "not", "string", "unfortun", "aw", "api", "accept", "either", "but", "will", "alway", "return", "integ", "fix", "5119"], "B_body": "Apply existing `normalizeJson` as `StateFunc` to SQS policy to prevent AWS from detecting policy changes when stripping whitespace characters. Labeled as bug in hashicorp/terraform#4273. Different resource, but appears to be a similar issue in hashicorp/terraform#4245 as well.\n", "B_clean_body": ["appli", "exist", "normalizejson", "normal", "json", "as", "statefunc", "state", "func", "sq", "polici", "prevent", "aw", "detect", "polici", "chang", "when", "strip", "whitespac", "charact", "label", "as", "bug", "hashicorp", "terraform", "4273", "differ", "resourc", "but", "appear", "similar", "issu", "hashicorp", "terraform", "4245", "as", "well"], "title_sim": [0.6693033845633182], "body_sim": [0.2645106493665557], "file_list_sim": 0.25, "overlap_files_len": 1, "code_sim": [0.07012632500613378, 0.333804552567586], "location_sim": [0.165, 0.66], "pattern": -1, "time": 67}, {"A_title": "[WIP] provider/aws: CloudFront", "A_clean_title": ["wip", "provid", "aw", "cloudfront", "cloud", "front"], "B_title": "provider/aws: CloudFront Distribution", "B_clean_title": ["provid", "aw", "cloudfront", "cloud", "front", "distribut"], "A_body": "Created a new PR as this is a rewritten implementation of my earlier attempt. The only feature not supported are multiple origins and behaviors.\n\nAlso worth noting is the fragility of the CloudFront API. Whenever a new attribute is added(DefaultTTL was added this summer) they are optional when creating the resource but not when updating an existing resource. Hopefully this does not happen too often.\n\nprevious PR: #1780\n\n@radeksimko @justincampbell @dalehamel\n", "A_clean_body": ["creat", "new", "pr", "as", "thi", "rewritten", "implement", "my", "earlier", "attempt", "onli", "featur", "not", "support", "are", "multipl", "origin", "behavior", "also", "worth", "note", "fragil", "cloudfront", "cloud", "front", "api", "whenev", "new", "attribut", "ad", "defaultttl", "default", "ttl", "wa", "ad", "thi", "summer", "they", "are", "option", "when", "creat", "resourc", "but", "not", "when", "updat", "exist", "resourc", "hope", "thi", "not", "happen", "too", "often", "previou", "pr", "1780", "radeksimko", "justincampbel", "dalehamel"], "B_body": "- [x] Schema\n- [x] Create Implementation\n- [ ] Read Implementation\n- [ ] Update Implementation\n- [ ] Delete Implementation\n- [ ] Acceptance Tests\n- [ ] Docs\n\nSeems like a few other folks started doing this before and didn't finish. I'm hoping I can do better by focusing only on the primary functionality in this first changeset, and then progressively more features in subsequent changesets.\n", "B_clean_body": ["schema", "creat", "implement", "read", "implement", "updat", "implement", "delet", "implement", "accept", "test", "doc", "seem", "like", "few", "other", "folk", "start", "do", "thi", "befor", "did", "n't", "finish", "'m", "hope", "better", "by", "focus", "onli", "primari", "function", "thi", "first", "changeset", "then", "progress", "more", "featur", "subsequ", "changeset"], "title_sim": [0.741812759950696], "body_sim": [0.30579608889179977], "file_list_sim": 0.2, "overlap_files_len": 3, "code_sim": [0.7520254156171918, 0.8403825242935036], "location_sim": [0.6119402985074627, 0.9469632164242943], "pattern": 0, "time": 9}, {"A_title": "docs/aws: Fix the discrepencies of the emr_cluster documentation", "A_clean_title": ["doc", "aw", "fix", "discrep", "emr", "cluster", "document"], "B_title": "`instance_profile` is a required parameter when creating an EMR instance group", "B_clean_title": ["instanc", "profil", "requir", "paramet", "when", "creat", "emr", "instanc", "group"], "A_body": "Fixes #10296", "A_clean_body": ["fix", "10296"], "B_body": "When creating an EC2 instance group to process data in an EMR cluster,\r\nspecifying `instance_profile` as an attribute inside `ec2_attributes` is\r\nmandatory, it would appear.\r\n\r\nNot setting it results in an error from Terraform complaining that it isn't\r\nset, and the AWS SDK for Go appears - at least in my interpretation - not to\r\ndefault it anywhere:\r\nhttps://github.com/aws/aws-sdk-go/blob/master/service/emr/api.go\r\n\r\nThis PR also includes some basic style and grammatical fixes.", "B_clean_body": ["when", "creat", "ec2", "instanc", "group", "process", "data", "emr", "cluster", "specifi", "instanc", "profil", "as", "attribut", "insid", "ec2", "attribut", "mandatori", "it", "would", "appear", "not", "set", "it", "result", "error", "terraform", "complain", "that", "it", "isn't", "set", "aw", "sdk", "go", "appear", "at", "least", "my", "interpret", "not", "default", "it", "anywher", "http", "sdk", "go", "github", "com", "aw", "aw", "go", "blob", "master", "servic", "emr", "api", "thi", "pr", "also", "includ", "some", "basic", "style", "grammat", "fix"], "title_sim": [0.057807010738342754], "body_sim": [0.07221054621512536], "file_list_sim": 1.0, "overlap_files_len": 1, "code_sim": [1.0, 1.0], "location_sim": [1.0, 1.0], "pattern": 0, "time": 35}, {"A_title": "provider/fastly Changes setting conditionals to optional", "A_clean_title": ["provid", "fastli", "chang", "set", "condit", "option"], "B_title": "provider/fastly: Make request_condition optional", "B_clean_title": ["provid", "fastli", "make", "request", "condit", "option"], "A_body": "Allows the user to create both `request_setting`s and `chache_setting`s with no conditional set. Conditionals were previously required, but this limits options that Fastly allows as shown [here](https://docs.fastly.com/guides/securing-communications/allowing-only-tls-connections-to-your-site)\r\n\r\n- [x] Website documentation updated\r\n\r\nCloses #13651 ", "A_clean_body": ["allow", "user", "creat", "both", "request", "set", "chach", "set", "no", "condit", "set", "condit", "were", "previous", "requir", "but", "thi", "limit", "option", "that", "fastli", "allow", "as", "shown", "here", "http", "onli", "tl", "connect", "your", "site", "fastli", "commun", "allow", "doc", "com", "guid", "secur", "websit", "document", "updat", "close", "13651"], "B_body": "Makes the `request_condition` setting optional for Fastly `request_settings` as seen here:\r\n\r\n![Fastly request setting example](https://docs.fastly.com/img/guides/only-tls-create-new-request.png)\r\n\r\nThis also updates the relevant documentation.\r\n", "B_clean_body": ["make", "request", "condit", "set", "option", "fastli", "request", "set", "as", "seen", "here", "fastli", "request", "set", "exampl", "http", "tl", "creat", "new", "fastli", "request", "png", "doc", "com", "img", "guid", "onli", "thi", "also", "updat", "relev", "document"], "title_sim": [0.37336675826410376], "body_sim": [0.6494744455460923], "file_list_sim": 1.0, "overlap_files_len": 2, "code_sim": [0.7225693799400911, 0.7225693799400911], "location_sim": [0.5833333333333334, 0.5833333333333334], "pattern": 0, "time": 1}, {"A_title": "Skip IAM/STS validation and metadata check", "A_clean_title": ["skip", "iam", "st", "valid", "metadata", "check"], "B_title": "add `validate_credentials` option to provider-aws", "B_clean_title": ["add", "valid", "credenti", "option", "provid", "aw"], "A_body": "Skip IAM/STS validation and metadata check\n- Skip IAM/STS identity validation - For environments or other api\n  implementations where there are no IAM/STS endpoints available, this\n  option lets you opt out from that provider initialization step.\n- Skip metdata api check - For environments in which you know ahead of\n  time there isn't going to be a metadta api endpoint, this option lets\n  you opt out from that check to save time.\n\nSample provider config:\n\n``` hcl\nprovider \"aws\" {\n  region = \"us-east-1\"\n  skip_iam_creds_validation = true\n  skip_iam_account_id = true\n  skip_metadata_api_check = true\n}\n```\n", "A_clean_body": ["skip", "iam", "st", "valid", "metadata", "check", "skip", "iam", "st", "ident", "valid", "environ", "or", "other", "api", "implement", "where", "there", "are", "no", "iam", "st", "endpoint", "avail", "thi", "option", "let", "you", "opt", "out", "that", "provid", "initi", "step", "skip", "metdata", "api", "check", "environ", "which", "you", "know", "ahead", "time", "there", "n't", "go", "metadta", "api", "endpoint", "thi", "option", "let", "you", "opt", "out", "that", "check", "save", "time", "sampl", "provid", "config", "hcl", "provid", "aw", "region", "us", "east", "skip", "iam", "cred", "valid", "true", "skip", "iam", "account", "id", "true", "skip", "metadata", "api", "check", "true"], "B_body": "My dev team is planning to use Terraform to manage our AWS resources in all of our environments (Dev, Test, and Prod).\n\nWe develop 100% locally (fake_sqs and DynamoDB Local) and do not have access to AWS credentials. We'd like to use Terraform to stand up tables against DynamoDB Local (or any other local AWS service).\n\nI added a `validate_credentials` option to the `provider-aws` Schema. It defaults to `true`. When set to `false` the credentials are not validated at all against IAM or the white / black list of account ids.\n\nSince DynamoDB Local does not check the validity of the credentials we can create tables against it. \n", "B_clean_body": ["my", "dev", "team", "plan", "use", "terraform", "manag", "our", "aw", "resourc", "all", "our", "environ", "dev", "test", "prod", "we", "develop", "100", "local", "fake", "sq", "dynamodb", "dynamo", "db", "local", "not", "have", "access", "aw", "credenti", "we", "'d", "like", "use", "terraform", "stand", "up", "tabl", "against", "dynamodb", "dynamo", "db", "local", "or", "ani", "other", "local", "aw", "servic", "ad", "valid", "credenti", "option", "provid", "aw", "schema", "it", "default", "true", "when", "set", "fals", "credenti", "are", "not", "valid", "at", "all", "against", "iam", "or", "white", "black", "list", "account", "id", "sinc", "dynamodb", "dynamo", "db", "local", "not", "check", "valid", "credenti", "we", "creat", "tabl", "against", "it"], "title_sim": [0.3205256885357034], "body_sim": [0.35704707686244075], "file_list_sim": 0.3333333333333333, "overlap_files_len": 2, "code_sim": [0.3216526516322489, 0.31115770220187633], "location_sim": [0.4363143631436314, 0.817258883248731], "pattern": 0, "time": 82}, {"A_title": "[WIP] provider/aws: Add support for AWS Config service", "A_clean_title": ["wip", "provid", "aw", "add", "support", "aw", "config", "servic"], "B_title": "provider/aws: Add support for AWSConfig service", "B_clean_title": ["provid", "aw", "add", "support", "awsconfig", "aw", "config", "servic"], "A_body": "Finishing off the work started by @stack72 in #3280", "A_clean_body": ["finish", "off", "work", "start", "by", "stack72", "3280"], "B_body": "### TODO\r\n- [x] Implementation of `aws_config_configuration_recorder`\r\n- [x] Implementation of `aws_config_configuration_recorder_status`\r\n- [x] Implementation of `aws_config_delivery_channel`\r\n- [x] Implementation of `aws_config_config_rule`\r\n- [x] Docs for `aws_config_configuration_recorder`\r\n- [x] Docs for `aws_config_configuration_recorder_status`\r\n- [x] Docs for `aws_config_delivery_channel`\r\n- [x] Docs for `aws_config_config_rule`\r\n- [x] Acceptance tests for `aws_config_configuration_recorder`\r\n- [x] Acceptance tests for `aws_config_configuration_recorder_status`\r\n- [x] Acceptance tests for `aws_config_delivery_channel`\r\n- [x] Acceptance tests for `aws_config_config_rule`\r\n- [x] `ValidateFunc` functions on all fields of all 4 resources where it makes sense\r\n- [x] Import of all 4 resources + tests\r\n- [x] Guard against deletion of all 4 resources outside of Terraform\r\n", "B_clean_body": ["todo", "implement", "aw", "config", "configur", "record", "implement", "aw", "config", "configur", "record", "statu", "implement", "aw", "config", "deliveri", "channel", "implement", "aw", "config", "config", "rule", "doc", "aw", "config", "configur", "record", "doc", "aw", "config", "configur", "record", "statu", "doc", "aw", "config", "deliveri", "channel", "doc", "aw", "config", "config", "rule", "accept", "test", "aw", "config", "configur", "record", "accept", "test", "aw", "config", "configur", "record", "statu", "accept", "test", "aw", "config", "deliveri", "channel", "accept", "test", "aw", "config", "config", "rule", "validatefunc", "valid", "func", "function", "all", "field", "all", "resourc", "where", "it", "make", "sens", "import", "all", "resourc", "test", "guard", "against", "delet", "all", "resourc", "outsid", "terraform"], "title_sim": [0.8678325272438574], "body_sim": [0.07032980490349754], "file_list_sim": 0, "overlap_files_len": 0, "code_sim": [0.0, 0.0], "location_sim": [0.0, 0.0], "pattern": 0, "time": 231}, {"A_title": "Fix AWS ECS placement strategy spread fields", "A_clean_title": ["fix", "aw", "ec", "placement", "strategi", "spread", "field"], "B_title": "Fix ECS field inconsistency", "B_clean_title": ["fix", "ec", "field", "inconsist"], "A_body": "Resubmitting PR #12199 based on master\r\n\r\nFix for #11844.\r\n\r\nAWS API requires ECS placement strategies \"field\" attribute to be\r\n\"memory\" or \"cpu\" (lowercase) when type=bin, but these read back as\r\n\"MEMORY\" and \"CPU\" (uppercase) respectively.\r\n\r\nPR #11565 (which fixed separately reported #11644) deals with this by\r\nalways lowering the case of the resource received from the API, but this\r\nbreaks for other \"field\" values (e.g. \"instanceId\" -> \"instanceid\").\r\n\r\nThis PR only lowers the case of the returned resource when field\r\n\"MEMORY\" or \"CPU\". Haven't checked if any other fields need this\r\ntreatment.", "A_clean_body": ["resubmit", "pr", "12199", "base", "master", "fix", "11844", "aw", "api", "requir", "ec", "placement", "strategi", "field", "attribut", "memori", "or", "cpu", "lowercas", "when", "type=bin", "but", "these", "read", "back", "as", "memori", "cpu", "uppercas", "respect", "pr", "11565", "which", "fix", "separ", "report", "11644", "deal", "thi", "by", "alway", "lower", "case", "resourc", "receiv", "api", "but", "thi", "break", "other", "field", "valu", "instanceid", "instanc", "id", "instanceid", "thi", "pr", "onli", "lower", "case", "return", "resourc", "when", "field", "memori", "or", "cpu", "have", "n't", "check", "ani", "other", "field", "need", "thi", "treatment"], "B_body": "ECS has some inconsistency in the way it sends down\r\nfield names and the way it expects them in the api.\r\n\r\n`MEMORY` and `CPU` are expected capitalized and `instanceId` should be sent as\r\nis.\r\n\r\nThe previous fixed lowercased everything, meaning `instanceId` is being\r\nsaved as `instanceid` and causing a change in the resource.\r\n\r\nPRs and issues\r\n\r\n* https://github.com/hashicorp/terraform/pull/12199\r\n* https://github.com/hashicorp/terraform/issues/11644\r\n* https://github.com/hashicorp/terraform/issues/11844", "B_clean_body": ["ec", "ha", "some", "inconsist", "way", "it", "send", "down", "field", "name", "way", "it", "expect", "them", "api", "memori", "cpu", "are", "expect", "capit", "instanceid", "instanc", "id", "sent", "as", "previou", "fix", "lowercas", "everyth", "mean", "instanceid", "instanc", "id", "be", "save", "as", "instanceid", "caus", "chang", "resourc", "pr", "rs", "issu", "http", "github", "com", "hashicorp", "terraform", "pull", "12199", "http", "github", "com", "hashicorp", "terraform", "issu", "11644", "http", "github", "com", "hashicorp", "terraform", "issu", "11844"], "title_sim": [0.33559981567380265], "body_sim": [0.3427173434510493], "file_list_sim": 1.0, "overlap_files_len": 1, "code_sim": [0.7233526124070923, 0.7233526124070923], "location_sim": [1.0, 1.0], "pattern": 1, "time": 5}, {"A_title": "provider/aws: Normalize IAM policy documents", "A_clean_title": ["provid", "aw", "normal", "iam", "polici", "document"], "B_title": "provider/aws: Fixing IAM data source policy generation to prevent spurious diffs", "B_clean_title": ["provid", "aw", "fix", "iam", "data", "sourc", "polici", "gener", "prevent", "spuriou", "diff"], "A_body": "Fixes #3634 and fixes #7495.\n\nTwo normalizations are applied:\n- Arrays of length 1 become single strings because this is how they are returned from AWS APIs.\n- Arrays of length more than 1 are sorted because AWS stores them as sets and returns them in random order.\n", "A_clean_body": ["fix", "3634", "fix", "7495", "two", "normal", "are", "appli", "array", "length", "becom", "singl", "string", "becaus", "thi", "how", "they", "are", "return", "aw", "api", "ap", "array", "length", "more", "than", "are", "sort", "becaus", "aw", "store", "them", "as", "set", "return", "them", "random", "order"], "B_body": "Just re-submitting this as a new PR, this was \"submitted\" in #6881.\n\nAs mentioned there, there are a number of things AWS likes to do with a policy (namely resource policies versus IAM ones), that cause spurious diffs in Terraform even though nothing has changed, ie: sorting arrays, inserting an empty `Sid` attribute, and converting single-element lists to a string value.\n\nHaving the data source affords us the opportunity to ensure that these problems do not persist as we can now tweak the policy generation in one place.\n\nAgain, an example of the issue in action:\n\nhttps://gist.github.com/vancluever/526e9c1d8153436e58244847b8fb20f1\n\nThe changes in this commit fixes things to allow a policy generated via the `aws_iam_policy_document` data source to properly pass a TF plan/apply without any changes when nothing has indeed changed.\n\nReferences for this: I list a few here, however if you search in the issue backlog there are more:\n\nS3: #6952\nSNS: #6909\nS3, discussing ordering: #5978\nElasticSearch: #5067\nMy original PR: #4278\n", "B_clean_body": ["just", "re", "submit", "thi", "as", "new", "pr", "thi", "wa", "submit", "6881", "as", "mention", "there", "there", "are", "number", "thing", "aw", "like", "polici", "name", "resourc", "polici", "versu", "iam", "one", "that", "caus", "spuriou", "diff", "terraform", "even", "though", "noth", "ha", "chang", "ie", "sort", "array", "insert", "empti", "sid", "attribut", "convert", "singl", "element", "list", "string", "valu", "have", "data", "sourc", "afford", "us", "opportun", "ensur", "that", "these", "problem", "not", "persist", "as", "we", "now", "tweak", "polici", "gener", "one", "place", "again", "exampl", "issu", "action", "http", "github", "gist", "com", "vancluev", "526e9c1d8153436e58244847b8fb20f1", "chang", "thi", "commit", "fix", "thing", "allow", "polici", "gener", "via", "aw", "iam", "polici", "document", "data", "sourc", "properli", "pass", "tf", "plan", "appli", "without", "ani", "chang", "when", "noth", "ha", "inde", "chang", "refer", "thi", "list", "few", "here", "howev", "you", "search", "issu", "backlog", "there", "are", "more", "s3", "6952", "sn", "6909", "s3", "discuss", "order", "5978", "elasticsearch", "elast", "search", "5067", "my", "origin", "pr", "4278"], "title_sim": [0.43091659423891754], "body_sim": [0.4452757080812546], "file_list_sim": 0.23076923076923078, "overlap_files_len": 3, "code_sim": [0.2622377900399289, 0.07362640790023932], "location_sim": [0.5622188905547226, 0.9765625], "pattern": -1, "time": 53}, {"A_title": "provider/aws: Add Security Group Rule as a top level resource", "A_clean_title": ["provid", "aw", "add", "secur", "group", "rule", "as", "top", "level", "resourc"], "B_title": "Breaking security group rules out into it's own resource to address #539", "B_clean_title": ["break", "secur", "group", "rule", "out", "into", "it", "'s", "own", "resourc", "address", "539"], "A_body": "First attempt at making Security Group Rules (ingress, egress) top level resources. \n\nThis is raw, like sushi, and probably needs refinement, but it's a good start.\n\nMissing:\n- [x]  documentation \n\ncc @phinze \n", "A_clean_body": ["first", "attempt", "at", "make", "secur", "group", "rule", "ingress", "egress", "top", "level", "resourc", "thi", "raw", "like", "sushi", "probabl", "need", "refin", "but", "it", "'s", "good", "start", "miss", "document", "cc", "phinz"], "B_body": "", "B_clean_body": [], "title_sim": [0.2936761850581668], "body_sim": [0.0], "file_list_sim": 0, "overlap_files_len": 0, "code_sim": [0.0, 0.0], "location_sim": [0.0, 0.0], "pattern": 0, "time": 20}, {"A_title": "[WIP] Allow multiple targets in an AWS ALB target group attachment", "A_clean_title": ["wip", "allow", "multipl", "target", "aw", "alb", "target", "group", "attach"], "B_title": "[WIP] Make the `port` attribute optional in the aws_alb_target_group_attachment resource.", "B_clean_title": ["wip", "make", "port", "attribut", "option", "aw", "alb", "target", "group", "attach", "resourc"], "A_body": "#9948 \r\n\r\n```\r\nresource \"aws_alb_target_group_attachment\" \"test\" {\r\n  target_group_arn = \"${aws_alb_target_group.test.arn}\"\r\n  targets {\r\n   target_id = \"${aws_instance.test.id}\"\r\n   port = 80\r\n  }\r\n  targets {\r\n   target_id = \"${aws_instance.demo.id}\"\r\n   port = 8080\r\n  }\r\n}\r\nresource \"aws_instance\" \"demo\" {\r\n  ami = \"ami-f701cb97\"\r\n  instance_type = \"t2.micro\"\r\n  subnet_id = \"${aws_subnet.subnet.id}\"\r\n}\r\nresource \"aws_instance\" \"test\" {\r\n  ami = \"ami-f701cb97\"\r\n  instance_type = \"t2.micro\"\r\n  subnet_id = \"${aws_subnet.subnet.id}\"\r\n}\r\nresource \"aws_alb_target_group\" \"test\" {\r\n  name = \"awsalbtargetgrouptest\"\r\n  port = 443\r\n  protocol = \"HTTPS\"\r\n  vpc_id = \"${aws_vpc.test.id}\"\r\n  deregistration_delay = 200\r\n  stickiness {\r\n    type = \"lb_cookie\"\r\n    cookie_duration = 10000\r\n  }\r\n  health_check {\r\n    path = \"/health\"\r\n    interval = 60\r\n    port = 8081\r\n    protocol = \"HTTP\"\r\n    timeout = 3\r\n    healthy_threshold = 3\r\n    unhealthy_threshold = 3\r\n    matcher = \"200-299\"\r\n  }\r\n}\r\nresource \"aws_subnet\" \"subnet\" {\r\n  cidr_block = \"10.0.1.0/24\"\r\n  vpc_id = \"${aws_vpc.test.id}\"\r\n}\r\nresource \"aws_vpc\" \"test\" {\r\n  cidr_block = \"10.0.0.0/16\"\r\n}\r\n```\r\nThis allows adding multiple targets with port to aws_alb_target_group_attachment but this will break existing rules. I am not sure what else we can do here.\r\n\r\nP.S i know this code can refactored not well written i will refactor but just to get heads up. \r\n\r\n@stack72 @paddyforan wdyt ?\r\n\r\nReferences:\r\n1) http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-targetgroup.html#cfn-elasticloadbalancingv2-targetgroup-targetattributes\r\n2) https://github.com/aws/aws-sdk-go/blob/master/service/elbv2/examples_test.go#L594-L603", "A_clean_body": ["9948", "resourc", "aw", "alb", "target", "group", "attach", "test", "target", "group", "arn", "test", "arn", "aw", "alb", "target", "group", "target", "target", "id", "test", "id", "aw", "instanc", "port", "80", "target", "target", "id", "demo", "id", "aw", "instanc", "port", "8080", "resourc", "aw", "instanc", "demo", "ami", "ami", "f701cb97", "instanc", "type", "t2", "micro", "subnet", "id", "subnet", "id", "aw", "subnet", "resourc", "aw", "instanc", "test", "ami", "ami", "f701cb97", "instanc", "type", "t2", "micro", "subnet", "id", "subnet", "id", "aw", "subnet", "resourc", "aw", "alb", "target", "group", "test", "name", "awsalbtargetgrouptest", "port", "443", "protocol", "http", "vpc", "id", "test", "id", "aw", "vpc", "deregistr", "delay", "200", "sticki", "type", "lb", "cooki", "cooki", "durat", "10000", "health", "check", "path", "health", "interv", "60", "port", "8081", "protocol", "http", "timeout", "healthi", "threshold", "unhealthi", "threshold", "matcher", "200", "299", "resourc", "aw", "subnet", "subnet", "cidr", "block", "10", "24", "vpc", "id", "test", "id", "aw", "vpc", "resourc", "aw", "vpc", "test", "cidr", "block", "10", "16", "thi", "allow", "ad", "multipl", "target", "port", "aw", "alb", "target", "group", "attach", "but", "thi", "will", "break", "exist", "rule", "am", "not", "sure", "what", "we", "here", "know", "thi", "code", "refactor", "not", "well", "written", "will", "refactor", "but", "just", "get", "head", "up", "stack72", "paddyforan", "wdyt", "refer", "http", "resourc", "elasticloadbalancingv2", "aw", "amazon", "targetgroup", "html", "doc", "com", "awscloudform", "latest", "userguid", "aw", "aw", "cloud", "format", "user", "guid", "cfn", "elasticloadbalancingv2", "targetgroup", "targetattribut", "http", "sdk", "go", "github", "com", "aw", "aw", "test", "go", "blob", "master", "servic", "elbv2", "exampl", "l594", "l603"], "B_body": "This commit makes the `port` attribute optional, allowing for the port number\r\nfor the target group to be used by default.\r\n\r\nSigned-off-by: Krzysztof Wilczynski <krzysztof.wilczynski@linux.com>", "B_clean_body": ["thi", "commit", "make", "port", "attribut", "option", "allow", "port", "number", "target", "group", "use", "by", "default", "sign", "off", "by", "krzysztof", "wilczynski", "krzysztof", "wilczynski", "linux", "com"], "title_sim": [0.6307921315265284], "body_sim": [0.37338769106775455], "file_list_sim": 0.5, "overlap_files_len": 1, "code_sim": [0.7998721412931845, 0.8027715680937596], "location_sim": [0.7962085308056872, 0.8235294117647058], "pattern": 0, "time": 8}, {"A_title": "AWS Instance `block_device` Attribute", "A_clean_title": ["aw", "instanc", "block", "devic", "attribut"], "B_title": "Aws volume size", "B_clean_title": ["aw", "volum", "size"], "A_body": "Added the ability to specify block devices for an AWS instance.\n\n```\nblock_device {\n  device_name = \"/dev/sda\"\n  volume_type = \"gp2\"\n  volume_size = 500\n}\n```\n", "A_clean_body": ["ad", "abil", "specifi", "block", "devic", "aw", "instanc", "block", "devic", "devic", "name", "dev", "sda", "volum", "type", "gp2", "volum", "size", "500"], "B_body": "This resolves #328 and allows for larger volume sizes on aws instances.\n", "B_clean_body": ["thi", "resolv", "328", "allow", "larger", "volum", "size", "aw", "instanc"], "title_sim": [0.3978029892603598], "body_sim": [0.466728094073906], "file_list_sim": 0.3333333333333333, "overlap_files_len": 1, "code_sim": [0.7719198376097638, 0.7412793533733313], "location_sim": [0.7056962025316456, 0.9369747899159664], "pattern": 0, "time": 16}, {"A_title": "docker provider additions", "A_clean_title": ["docker", "provid", "addit"], "B_title": "Implement restart policy support in Docker provider.", "B_clean_title": ["implement", "restart", "polici", "support", "docker", "provid"], "A_body": "Adds the following functionality to the `docker_container` resource:\n- support for setting the entrypoint\n- support for setting the restart policy (off|on-failure|always)\n- support for setting memory, memory-swap, and cpu-shares runtime constraints \n- support for docker labels\n- support for log-driver and log-options\n- includes HostConfig when creating container\n", "A_clean_body": ["add", "follow", "function", "docker", "contain", "resourc", "support", "set", "entrypoint", "support", "set", "restart", "polici", "off|on", "failure|alway", "support", "set", "memori", "memori", "swap", "cpu", "share", "runtim", "constraint", "support", "docker", "label", "support", "log", "driver", "log", "option", "includ", "hostconfig", "host", "config", "when", "creat", "contain"], "B_body": "Fixes #2417 \n", "B_clean_body": ["fix", "2417"], "title_sim": [0.6400367131305814], "body_sim": [-0.016662722570934967], "file_list_sim": 0.75, "overlap_files_len": 3, "code_sim": [0.29471808249482934, 0.20414436033303915], "location_sim": [0.3146341463414634, 0.45422535211267606], "pattern": 0, "time": 20}, {"A_title": "Initial SQS support", "A_clean_title": ["initi", "sq", "support"], "B_title": "provider/aws: adding support for SQS queues", "B_clean_title": ["provid", "aw", "ad", "support", "sq", "queue"], "A_body": "Initial support for making / updating / removing SQS queues; feedback welcome.\n", "A_clean_body": ["initi", "support", "make", "updat", "remov", "sq", "queue", "feedback", "welcom"], "B_body": "Disclaimer, I'm pretty new to Go but this seems to be working in my tests for adding/editing/delete a queue. It also passed `make test` but I might be doing things wrong\n\nThis adds basic SQS functionality to create/edit/delete a SQS queue. Right now it doesn't support anything like dead letter or permissions.\n\nLet me know if anything really bad or something I missed sticks out\n", "B_clean_body": ["disclaim", "'m", "pretti", "new", "go", "but", "thi", "seem", "work", "my", "test", "ad", "edit", "delet", "queue", "it", "also", "pass", "make", "test", "but", "might", "do", "thing", "wrong", "thi", "add", "basic", "sq", "function", "creat", "edit", "delet", "sq", "queue", "right", "now", "it", "n't", "support", "anyth", "like", "dead", "letter", "or", "permiss", "let", "me", "know", "anyth", "realli", "bad", "or", "someth", "miss", "stick", "out"], "title_sim": [0.5053224315020368], "body_sim": [0.16813764519739452], "file_list_sim": 0.2222222222222222, "overlap_files_len": 2, "code_sim": [0.9470775959683464, 1.0], "location_sim": [0.0546875, 0.7], "pattern": 0, "time": 2}, {"A_title": "enabled openstack plugin reading env values", "A_clean_title": ["enabl", "openstack", "plugin", "read", "env", "valu"], "B_title": "Correct Proxy setting for openstack provider: issue 8735", "B_clean_title": ["correct", "proxi", "set", "openstack", "provid", "issu", "8735"], "A_body": "", "A_clean_body": [], "B_body": "Correction of the Issue #8735 to use openstack provider trought a proxy.\n", "B_clean_body": ["correct", "issu", "8735", "use", "openstack", "provid", "trought", "proxi"], "title_sim": [0.3667861435796275], "body_sim": [0.0], "file_list_sim": 1.0, "overlap_files_len": 1, "code_sim": [1.0000000000000002, 1.0000000000000002], "location_sim": [1.0, 1.0], "pattern": 0, "time": 6}, {"A_title": "provider/aws: add response parameters support to api gateway", "A_clean_title": ["provid", "aw", "add", "respons", "paramet", "support", "api", "gateway"], "B_title": "provider/aws: Respect 'selection_pattern' in api_gateway_integration_response", "B_clean_title": ["provid", "aw", "respect", "'select", "pattern", "api", "gateway", "integr", "respons"], "A_body": "", "A_clean_body": [], "B_body": "Fixes #5891 \n", "B_clean_body": ["fix", "5891"], "title_sim": [0.7665673820153291], "body_sim": [0.0], "file_list_sim": 0.42857142857142855, "overlap_files_len": 3, "code_sim": [0.3252653651526932, 0.35677996486573543], "location_sim": [0.20416666666666666, 0.3843137254901961], "pattern": 0, "time": 27}, {"A_title": "provider/aws: aws_db_option_group normalizes name to lowercase", "A_clean_title": ["provid", "aw", "aw", "db", "option", "group", "normal", "name", "lowercas"], "B_title": "provider/aws require db option group name to be lower case", "B_clean_title": ["provid", "aw", "requir", "db", "option", "group", "name", "lower", "case"], "A_body": "This fixes #11040. The code here lowercases the name and/or prefix before sending it to the AWS API and the terraform state. This means the state will match the actual resource name and be able to converge the diff.\r\n\r\nOther providers might validate and throw an error or warning instead of just letting it work, but this is consistent with `aws_db_instance`. If this is the wrong approach, I can use a validator instead.\r\n\r\nI've also updated *all* the tests to include uppercase letters, which might be overkill.", "A_clean_body": ["thi", "fix", "11040", "code", "here", "lowercas", "name", "or", "prefix", "befor", "send", "it", "aw", "api", "terraform", "state", "thi", "mean", "state", "will", "match", "actual", "resourc", "name", "abl", "converg", "diff", "other", "provid", "might", "valid", "throw", "error", "or", "warn", "instead", "just", "let", "it", "work", "but", "thi", "consist", "aw", "db", "instanc", "thi", "wrong", "approach", "use", "valid", "instead", "'ve", "also", "updat", "*all*", "test", "includ", "uppercas", "letter", "which", "might", "overkil"], "B_body": "AWS is automatically changing these names to lower case as described in #11040 \r\nThis is causing errors when terraform apply is re-run.\r\n\r\nI don't believe this needs any documentation updates.\r\n\r\nCloses #11040", "B_clean_body": ["aw", "automat", "chang", "these", "name", "lower", "case", "as", "describ", "11040", "thi", "caus", "error", "when", "terraform", "appli", "re", "run", "n't", "believ", "thi", "need", "ani", "document", "updat", "close", "11040"], "title_sim": [0.8411936493067618], "body_sim": [0.4720596510732575], "file_list_sim": 0.6666666666666666, "overlap_files_len": 2, "code_sim": [0.23600562152127721, 0.052494570742779884], "location_sim": [0.1827956989247312, 0.20481927710843373], "pattern": 1, "time": 116}, {"A_title": "provider/google: Fix instance/template metadata support", "A_clean_title": ["provid", "googl", "fix", "instanc", "templat", "metadata", "support"], "B_title": "provider/google: instance template support for metadata_startup_script", "B_clean_title": ["provid", "googl", "instanc", "templat", "support", "metadata", "startup", "script"], "A_body": "Update our instance template to include metadata_startup_script, to\r\nmatch our instance resource. Also, we've resolved the diff errors around\r\nmetadata.startup-script, and people want to use that to create startup\r\nscripts that don't force a restart when they're changed, so let's stop\r\ndisallowing it.\r\n\r\nAlso, we had a bunch of calls to `schema.ResourceData.Set` that ignored\r\nthe errors, so I added error handling for those calls. It's mostly\r\nbundled with this code because I couldn't be sure whether it was the\r\nroot of bugs or not, so I took care of it while addressing the startup\r\nscript issue.\r\n\r\n**Notes:**\r\n* When _importing_ instance templates, we assume any startup scripts are for `metadata.startup-script`. This means we can't do an import test for `metadata_startup_script` because it will check for `metadata_startup_script` in the state, and it will get `metadata.startup-script` instead. We have to make this assumption because until we have state to work off, we can't detect that `metadata_startup_script` was used. Imports (to my knowledge?) don't have any state, so we can't figure out what the user specified. This does mean when a template is imported, then its conf file is created, if the conf file uses `metadata_startup_script`, the next `terraform plan` will show changes to use `metadata_startup_script` in the state, instead.\r\n* Changing from `metadata.startup-script` to `metadata_startup_script` requires a destroy/create. I don't know of a good way around this, or if this should even be the desired behaviour.\r\n* In the event that both `metadata.startup-script` _and_ `metadata_startup_script` are specified, `metadata_startup_script` wins.\r\n* `metadata_startup_script` is for instances that should be destroyed/recreated when the startup script changes. `metadata.startup-script` is for instances that want to modify it without a destroy/recreate. Instance templates destroy and recreate on metadata changes, anyways, so there's no real reason to use `metadata_startup_script` in an instance template, but cutting down on the inconsistencies between resources seems like a nice thing to do.\r\n\r\nThis undoes the work @phinze did in #3507, so pinging him. See also #10227, where @JDiPierro, @cblecker, and @sparkprime weighed in on the importance of having both supported for instances.", "A_clean_body": ["updat", "our", "instanc", "templat", "includ", "metadata", "startup", "script", "match", "our", "instanc", "resourc", "also", "we", "'ve", "resolv", "diff", "error", "around", "script", "metadata", "startup", "peopl", "want", "use", "that", "creat", "startup", "script", "that", "n't", "forc", "restart", "when", "they", "'re", "chang", "so", "let", "'s", "stop", "disallow", "it", "also", "we", "had", "bunch", "call", "schema", "resourcedata", "set", "resourc", "data", "that", "ignor", "error", "so", "ad", "error", "handl", "those", "call", "it", "'s", "mostli", "bundl", "thi", "code", "becaus", "could", "n't", "sure", "whether", "it", "wa", "root", "bug", "or", "not", "so", "took", "care", "it", "while", "address", "startup", "script", "issu", "**note", "when", "import", "instanc", "templat", "we", "assum", "ani", "startup", "script", "are", "script", "metadata", "startup", "thi", "mean", "we", "ca", "n't", "import", "test", "metadata", "startup", "script", "becaus", "it", "will", "check", "metadata", "startup", "script", "state", "it", "will", "get", "script", "metadata", "startup", "instead", "we", "have", "make", "thi", "assumpt", "becaus", "until", "we", "have", "state", "work", "off", "we", "ca", "n't", "detect", "that", "metadata", "startup", "script", "wa", "use", "import", "my", "knowledg", "n't", "have", "ani", "state", "so", "we", "ca", "n't", "figur", "out", "what", "user", "specifi", "thi", "mean", "when", "templat", "import", "then", "it", "conf", "file", "creat", "conf", "file", "use", "metadata", "startup", "script", "next", "terraform", "plan", "will", "show", "chang", "use", "metadata", "startup", "script", "state", "instead", "chang", "script", "metadata", "startup", "metadata", "startup", "script", "requir", "destroy", "creat", "n't", "know", "good", "way", "around", "thi", "or", "thi", "even", "desir", "behaviour", "event", "that", "both", "script", "metadata", "startup", "metadata", "startup", "script", "are", "specifi", "metadata", "startup", "script", "win", "metadata", "startup", "script", "instanc", "that", "destroy", "recreat", "when", "startup", "script", "chang", "script", "metadata", "startup", "instanc", "that", "want", "modifi", "it", "without", "destroy", "recreat", "instanc", "templat", "destroy", "recreat", "metadata", "chang", "anyway", "so", "there", "'s", "no", "real", "reason", "use", "metadata", "startup", "script", "instanc", "templat", "but", "cut", "down", "inconsist", "between", "resourc", "seem", "like", "nice", "thing", "thi", "undo", "work", "phinz", "did", "3507", "so", "ping", "him", "see", "also", "10227", "where", "jdipierro", "di", "pierro", "cblecker", "sparkprim", "weigh", "import", "have", "both", "support", "instanc"], "B_body": "Fixes #7827.\n\nThis pull updates the `google_compute_instance_template` resource to use the same metadata arguments and validation functions as the `google_compute_instance` resource. That being said, while this directly addresses the issue, I'm not sure it's the most graceful way of doing it for a couple of reasons.\n\nFor users with existing configuration, this will force them to migrate their:\n\n``` hcl\nmetadata {\n    startup-script = \"echo hi > /test.txt\"\n}\n```\n\nto: \n\n``` hcl\nmetadata_startup_script = \"echo hi > /test.txt\"\n```\n\nThis results in a plan that detects a change to the config and forces deletion and recreation of the template. If that template is in use by a `google_compute_instance_group_manager` resource, then the apply will fail as a template can't be deleted while in use. Then you'd need to taint the instance group which would delete and recreate all instances created by it.\n\nSecond, this change isn't strictly necessary. While it is good to have consistent configuration, functions, and validations where possible between the two resources, instance templates are more restrictive than instances. As an existing instance template can't be updated at all, any change of any metadata at all results in the above deletion and recreation scenario. The original reason as far as I can tell for splitting the main metadata apart from the startup script was that if the startup script changed, then the instance should be destroyed and recreated so that it can be re-run. This left the remaining metadata keys to be changed freely. As all metadata is treated the same here splitting the startup script out isn't really needed.\n\nPerhaps a state migration would solve this? Or perhaps it's not worth the hassle and is simply a WONTFIX. Thoughts? :)\n", "B_clean_body": ["fix", "7827", "thi", "pull", "updat", "googl", "comput", "instanc", "templat", "resourc", "use", "same", "metadata", "argument", "valid", "function", "as", "googl", "comput", "instanc", "resourc", "that", "be", "said", "while", "thi", "directli", "address", "issu", "'m", "not", "sure", "it", "'s", "most", "grace", "way", "do", "it", "coupl", "reason", "user", "exist", "configur", "thi", "will", "forc", "them", "migrat", "their", "hcl", "metadata", "startup", "script", "echo", "hi", "txt", "test", "hcl", "metadata", "startup", "script", "echo", "hi", "txt", "test", "thi", "result", "plan", "that", "detect", "chang", "config", "forc", "delet", "recreat", "templat", "that", "templat", "use", "by", "googl", "comput", "instanc", "group", "manag", "resourc", "then", "appli", "will", "fail", "as", "templat", "ca", "n't", "delet", "while", "use", "then", "you", "'d", "need", "taint", "instanc", "group", "which", "would", "delet", "recreat", "all", "instanc", "creat", "by", "it", "second", "thi", "chang", "n't", "strictli", "necessari", "while", "it", "good", "have", "consist", "configur", "function", "valid", "where", "possibl", "between", "two", "resourc", "instanc", "templat", "are", "more", "restrict", "than", "instanc", "as", "exist", "instanc", "templat", "ca", "n't", "updat", "at", "all", "ani", "chang", "ani", "metadata", "at", "all", "result", "abov", "delet", "recreat", "scenario", "origin", "reason", "as", "far", "as", "tell", "split", "main", "metadata", "apart", "startup", "script", "wa", "that", "startup", "script", "chang", "then", "instanc", "destroy", "recreat", "so", "that", "it", "re", "run", "thi", "left", "remain", "metadata", "key", "chang", "freeli", "as", "all", "metadata", "treat", "same", "here", "split", "startup", "script", "out", "n't", "realli", "need", "perhap", "state", "migrat", "would", "solv", "thi", "or", "perhap", "it", "'s", "not", "worth", "hassl", "simpli", "wontfix", "thought"], "title_sim": [0.9532736661547085], "body_sim": [0.7932810861235748], "file_list_sim": 0.75, "overlap_files_len": 3, "code_sim": [0.6485696384684145, 0.7078288709399432], "location_sim": [0.6952054794520548, 0.7518518518518519], "pattern": -1, "time": 104}, {"A_title": "Allow AWS ELB resource name to be computed", "A_clean_title": ["allow", "aw", "elb", "resourc", "name", "comput"], "B_title": "provider/aws: Allow ELB name to be generated", "B_clean_title": ["provid", "aw", "allow", "elb", "name", "gener"], "A_body": "To allow ease use with create_before_destroy\n", "A_clean_body": ["allow", "eas", "use", "creat", "befor", "destroy"], "B_body": "Since ELB has a hard limit of 32 characters, it may be sometimes hard to come up with a unique name, so user may end up just using tags for human labels, but the name still need to be filled in with something unique (although useless for humans).\n\nThis PR is adding new helper - indirectly related to #2269 and makes elb name optional - i.e. generated as `tf-lb-UNIQUE_ID`.\n\nI can add an acceptance test case for ELB w/out a name, but first I want to get general feedback on this idea.\n", "B_clean_body": ["sinc", "elb", "ha", "hard", "limit", "32", "charact", "it", "may", "sometim", "hard", "come", "up", "uniqu", "name", "so", "user", "may", "end", "up", "just", "tag", "human", "label", "but", "name", "still", "need", "fill", "someth", "uniqu", "although", "useless", "human", "thi", "pr", "ad", "new", "helper", "indirectli", "relat", "2269", "make", "elb", "name", "option", "gener", "as", "tf", "lb", "uniqu", "id", "add", "accept", "test", "case", "elb", "out", "name", "but", "first", "want", "get", "gener", "feedback", "thi", "idea"], "title_sim": [0.7592367355856464], "body_sim": [0.18022544945999233], "file_list_sim": 0.3333333333333333, "overlap_files_len": 1, "code_sim": [0.195782098110643, 0.39620323749573083], "location_sim": [0.2191780821917808, 0.3333333333333333], "pattern": 0, "time": 6}, {"A_title": "Add -update flag to init command", "A_clean_title": ["add", "updat", "flag", "init", "command"], "B_title": "command: Add flag for updating modules on init.", "B_clean_title": ["command", "add", "flag", "updat", "modul", "init"], "A_body": "Add the `-update` flag to the `init` command so modules can be updated if necessary without the need to use `terraform get`\r\n", "A_clean_body": ["add", "updat", "flag", "init", "command", "so", "modul", "updat", "necessari", "without", "need", "use", "terraform", "get"], "B_body": "Add a flag `update-modules` to enable updating modules as part of a `terraform init`, and supporting test case.\r\n\r\nThe justification behind this is to enable the use of `terraform init` as part of a Jenkins CI pipeline, whereby we are running a `terraform init` on every build. Currently, after the modules are initially downloaded they'll never be updated, unless either:\r\n* The workspace is cleared \r\n-or-\r\n* A `terraform get -update` is run", "B_clean_body": ["add", "flag", "updat", "modul", "enabl", "updat", "modul", "as", "part", "terraform", "init", "support", "test", "case", "justif", "behind", "thi", "enabl", "use", "terraform", "init", "as", "part", "jenkin", "ci", "pipelin", "wherebi", "we", "are", "run", "terraform", "init", "everi", "build", "current", "after", "modul", "are", "initi", "download", "they", "'ll", "never", "updat", "unless", "either", "workspac", "clear", "or", "terraform", "get", "updat", "run"], "title_sim": [0.8906710560262172], "body_sim": [0.6639418111550072], "file_list_sim": 0.6666666666666666, "overlap_files_len": 2, "code_sim": [0.6348524319034765, 0.9439130882766863], "location_sim": [0.7612903225806451, 1.0], "pattern": 0, "time": 24}, {"A_title": "provider/azurerm: Add `azurerm_dns_zone` resource", "A_clean_title": ["provid", "azurerm", "add", "azurerm", "dn", "zone", "resourc"], "B_title": "[WIP] provider/azurerm: add dns zone resource", "B_clean_title": ["wip", "provid", "azurerm", "add", "dn", "zone", "resourc"], "A_body": "This resource is the first which makes use of the new Riviera library (at https://github.com/jen20/riviera), so there is some additional set up work to add the provider to the client which gets passed among resources.\n", "A_clean_body": ["thi", "resourc", "first", "which", "make", "use", "new", "riviera", "librari", "at", "http", "github", "com", "jen20", "riviera", "so", "there", "some", "addit", "set", "up", "work", "add", "provid", "client", "which", "get", "pass", "among", "resourc"], "B_body": "Scaffold the ARM DNS Zone resource\n- [ ] Schema\n- [ ] CRUD\n- [ ] Acceptance Tests\n- [ ] Documentation\n\n```\nTest Results\n```\n\nUnfortunately there seems to be a bug in the Azure-go-sdk right now - https://github.com/Azure/azure-sdk-for-go/issues/260\n\nThis will need fixed before I can fix this\n", "B_clean_body": ["scaffold", "arm", "dn", "zone", "resourc", "schema", "crud", "accept", "test", "document", "test", "result", "unfortun", "there", "seem", "bug", "azur", "go", "sdk", "right", "now", "http", "sdk", "go", "issu", "260", "github", "com", "azur", "azur", "thi", "will", "need", "fix", "befor", "fix", "thi"], "title_sim": [0.8144858767350845], "body_sim": [0.2806924328895122], "file_list_sim": 0.16, "overlap_files_len": 4, "code_sim": [0.6018684402993258, 0.9080597425972041], "location_sim": [0.30612244897959184, 0.8893280632411067], "pattern": 0, "time": 21}]